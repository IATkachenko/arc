<?xml version="1.0"?>
<ArcConfig
  xmlns="http://www.nordugrid.org/schemas/ArcConfig/2007"
  xmlns:tcp="http://www.nordugrid.org/schemas/ArcMCCTCP/2007"
  xmlns:arex="http://www.nordugrid.org/schemas/ArcConfig/2009/arex"
  xmlns:info="http://www.nordugrid.org/schemas/ArcConfig/2009/arex/InfoProvider"
  xmlns:lrms="http://www.nordugrid.org/schemas/ArcConfig/2009/arex/LRMS"
>
  <!-- Common configuration of the daemon -->
  <Server>
    <PidFile>/var/run/arched.pid</PidFile>
    <Logger level="VERBOSE">/var/log/arched.log</Logger>
  </Server>
  <!-- Where to find plugins -->
  <ModuleManager>
    <Path>@prefix@/lib/arc/</Path>
  </ModuleManager>
  <!-- Simply load all needed plugins -->
  <Plugins><Name>mcctcp</Name></Plugins>
  <Plugins><Name>mcctls</Name></Plugins>
  <Plugins><Name>mcchttp</Name></Plugins>
  <Plugins><Name>mccsoap</Name></Plugins>
  <Plugins><Name>arcpdc</Name></Plugins>
  <Plugins><Name>identitymap</Name></Plugins>
  <Plugins><Name>arex</Name></Plugins>
  <!-- Create a chain -->
  <Chain>
    <!-- TCP listening socket -->
    <Component name="tcp.service" id="tcp">
      <next id="tls"/>
      <tcp:Listen><tcp:Port>60000</tcp:Port></tcp:Listen>
    </Component>
    <!-- Transport-level security -->
    <Component name="tls.service" id="tls">
      <next id="http"/>
      <!-- Location of server's security keys -->
      <KeyPath>/etc/grid-security/hostkey.pem</KeyPath>
      <CertificatePath>/etc/grid-security/hostcert.pem</CertificatePath>
      <CACertificatesDir>/etc/grid-security/certificates</CACertificatesDir>
      <!-- SecHandler below calls specified Policy Decision Point components.
           In this example only one PDP is defined - simplelist.pdp. This
	   PDP compares Distinguished Name of connecting client against
	   list of allowed DNs. DNs are stored in external file one per line.
	   They may be enclosed in '"'. -->
      <SecHandler name="arc.authz" id="pdps" event="incoming">
        <PDP name="simplelist.pdp" location="/etc/grid-security/grid-mapfile"/>
      </SecHandler>
      <!-- Evaluate requestor's identity into local identity.
           Comment it if no user mapping is needed. -->
      <SecHandler name="identity.map" id="map" event="incoming">
        <!-- Safe choice if all other rules failed -->
        <PDP name="allow.pdp"><LocalName>nobody</LocalName></PDP>
      </SecHandler>
    </Component>
    <!-- HTTP processing is done here -->
    <Component name="http.service" id="http">
      <next id="soap">POST</next>
      <next id="plexer">GET</next>
      <next id="plexer">PUT</next>
    </Component>
    <!-- This one parses content into XML tree -->
    <Component name="soap.service" id="soap">
      <next id="plexer"/>
    </Component>
    <!-- Directing messages to proper service -->
    <Plexer name="plexer.service" id="plexer">
      <next id="a-rex">^/arex</next>
    </Plexer>
    <!-- A-Rex service -->
    <Service name="a-rex" id="a-rex">
      <!-- Optional endpoint element is advised in case of multiple IP adresses -->
      <arex:endpoint>https://localhost:60000/arex</arex:endpoint>
      <!-- Use information generated by identity.map plugin or default provided below -->
      <arex:usermap><arex:defaultLocalName>nobody</arex:defaultLocalName></arex:usermap>

      <arex:gmrun>internal</arex:gmrun>
      <arex:commonName>A-REX</arex:commonName>
      <arex:longDescription>ARC execution service</arex:longDescription>
      <arex:LRMSName>pbs</arex:LRMSName>
      <arex:OperatingSystem>LINUX</arex:OperatingSystem>
      <arex:debugLevel>DEBUG</arex:debugLevel>
      <arex:InfoproviderWakeupPeriod>30</arex:InfoproviderWakeupPeriod>
      <arex:loadLimits>
          <arex:maxJobsTracked>1000</arex:maxJobsTracked>
          <arex:maxJobsRun>100</arex:maxJobsRun>
          <arex:maxJobsTransfered>20</arex:maxJobsTransfered>
          <arex:maxJobsTransferedAdditional>2</arex:maxJobsTransferedAdditional>
          <arex:maxFilesTransfered>4</arex:maxFilesTransfered>
          <arex:maxJobsPerShare shareType="voms:vo">50</arex:maxJobsPerShare>
          <arex:maxJobsPerShare shareType="voms:role">10</arex:maxJobsPerShare>
          <arex:maxJobsPerShare shareType="dn">4</arex:maxJobsPerShare>
          <arex:wakeupPeriod>30</arex:wakeupPeriod>
      </arex:loadLimits>
      <arex:dataTransfer>
          <arex:secureTransfer>true</arex:secureTransfer>
          <arex:passiveTransfer>true</arex:passiveTransfer>
          <arex:localTransfer>true</arex:localTransfer>
          <arex:timeouts>
              <arex:minSpeed>50</arex:minSpeed>
              <arex:minSpeedTime>300</arex:minSpeedTime>
              <arex:minAverageSpeed>200</arex:minAverageSpeed>
              <arex:maxInactivityTime>300</arex:maxInactivityTime>
          </arex:timeouts>
          <arex:maxRetries>4</arex:maxRetries>
          <arex:mapURL>
              <arex:from>gsiftp://example.org:2811/data/</arex:from>
              <arex:to>/local/data/</arex:to>
              <arex:link>true</arex:link>
          </arex:mapURL>
          <arex:mapURL>
              <arex:from>gsiftp://other.org/path/</arex:from>
              <arex:to>/local/path/</arex:to>
              <arex:link>false</arex:link>
          </arex:mapURL>
          <arex:Globus>
              <arex:gridmapfile>/etc/grid-security/grid-mapfile</arex:gridmapfile>
              <arex:cadir>/etc/grid-security/certificates</arex:cadir>
              <arex:certpath>/etc/grid-security/hostcert.pem</arex:certpath>
              <arex:keypath>/etc/grid-security/hostkey.pem</arex:keypath>
              <arex:TCPPortRange>80000-90000</arex:TCPPortRange>
              <arex:UDPPortRange>80000-90000</arex:UDPPortRange>
              <arex:httpProxy>http://proxy.org:8080</arex:httpProxy>
          </arex:Globus>
      </arex:dataTransfer>
      <arex:jobLogPath>/var/log/arex-jobs.log</arex:jobLogPath>
      <arex:jobReport>
          <arex:destination>https://grid.uio.no:8001/logger</arex:destination>
          <arex:expiration>26800</arex:expiration>
          <arex:type>SGAS</arex:type>
          <arex:parameters>ddd</arex:parameters>
      </arex:jobReport>
      <arex:authPlugin>
          <arex:state>ACCEPTED</arex:state>
          <arex:command>/opt/nordugrid/libexec/bank %C/job.%I.local %S</arex:command>
          <arex:timeout>20</arex:timeout>
          <arex:onSuccess>PASS</arex:onSuccess>
          <arex:onFailure>FAIL</arex:onFailure>
          <arex:onTimeout>FAIL</arex:onTimeout>
      </arex:authPlugin>
      <arex:control>
          <arex:username></arex:username>
          <arex:controlDir>/data/jobstatus</arex:controlDir>
          <arex:sessionRootDir>/cluster/charged/sessions</arex:sessionRootDir>
          <arex:sessionRootDir>/cluster/charged/sessions2</arex:sessionRootDir>
          <arex:cache>
              <arex:location>/cluster/charged/cache</arex:location>
              <arex:link>/mnt/cache</arex:link>
              <arex:highWatermark>90</arex:highWatermark>
              <arex:lowWatermark>70</arex:lowWatermark>
          </arex:cache>
          <arex:cache type="REMOTE" replicate="true">
              <arex:location>/data/export/cache</arex:location>
              <arex:highWatermark>90</arex:highWatermark>
              <arex:lowWatermark>70</arex:lowWatermark>
          </arex:cache>
          <arex:defaultTTL>259200</arex:defaultTTL>
          <arex:defaultTTR>2592000</arex:defaultTTR>
          <arex:maxReruns>5</arex:maxReruns>
          <arex:noRootPower>false</arex:noRootPower>
      </arex:control>

      <arex:helperUtility>
          <arex:username>grid01</arex:username>
          <arex:path>/usr/local/bin/myutility</arex:path>
      </arex:helperUtility>
      <arex:helperUtility>
          <arex:username>root</arex:username>
          <arex:path>/opt/ng/bin/cache-clean</arex:path>
      </arex:helperUtility>

      <arex:serviceMail>support@cluster.org</arex:serviceMail>
      <arex:runtimeDir>/data/export/SOFTWARE</arex:runtimeDir>
      <arex:scratchDir>/tmp</arex:scratchDir>
      <arex:tmpDir>/tmp</arex:tmpDir>
      <arex:sharedFilesystem>true</arex:sharedFilesystem>
      <arex:GNUTimeUtility>/usr/bin/time</arex:GNUTimeUtility>

      <arex:LRMS>
          <arex:type>pbs</arex:type>
          <arex:defaultShare>knowarc</arex:defaultShare>

          <lrms:maui_bin_path>/usr/local/bin</lrms:maui_bin_path>
          <lrms:pbs_bin_path>/opt/torque/bin</lrms:pbs_bin_path>
          <lrms:pbs_log_path>/usr/spool/torque/server_logs</lrms:pbs_log_path>
          <!--lrms:dedicated_node_string>gridnode</lrms:dedicated_node_string-->
          <lrms:condor_location>/opt/condor</lrms:condor_location>
          <lrms:condor_config>/opt/condor/etc/condor_config</lrms:condor_config>
          <lrms:condor_rank>(1-LoadAvg/2)*(1-LoadAvg/2)*Memory/1000*KFlops/1000000</lrms:condor_rank>
          <lrms:sge_bin_path>/opt/n1ge6/bin/lx24-x86</lrms:sge_bin_path>
          <lrms:sge_root>/opt/n1ge6</lrms:sge_root>
          <lrms:sge_cell>default</lrms:sge_cell>
          <lrms:sge_qmaster_port>536</lrms:sge_qmaster_port>
          <lrms:sge_execd_port>537</lrms:sge_execd_port>
          <lrms:lsf_bin_path>/usr/local/lsf/bin/</lrms:lsf_bin_path>
          <lrms:lsf_profile_path>/usr/share/lsf/conf</lrms:lsf_profile_path>
          <lrms:lsf_architecture>ia64</lrms:lsf_architecture>
          <lrms:ll_bin_path>/opt/ibmll/LoadL/full/bin</lrms:ll_bin_path>
          <lrms:ll_consumable_resources>yes</lrms:ll_consumable_resources>
          <lrms:slurm_bin_path>/usr/bin</lrms:slurm_bin_path>
      </arex:LRMS>

      <info:infoProvider>
          <info:clusterName>Titan</info:clusterName> <!-- ComputingService.Name -->
          <info:clusterDetails>This cluster is specially designed for XYZ applications: www.xyz.org</info:clusterDetails> <!-- ComputingService.OtherInfo -->
          <info:lrmsDetails>single job per processor</info:lrmsDetails> <!-- ComputingManager.OtherInfo -->
          <info:statusInfoPage>http://mycluster.org/monitor</info:statusInfoPage> <!-- ComputingService.StatusInfo -->
          <info:statusInfoPage>http://mycluster.org/ganglia/</info:statusInfoPage>
          <info:connectivityIn>false</info:connectivityIn> <!-- ExecutionEnvironment.ConnectivityIn -->
          <info:connectivityOut>true</info:connectivityOut> <!-- ExecutionEnvironment.ConnectivityOut -->
          <info:networkInfo>gbitethernet</info:networkInfo> <!-- can also be specified on a per-nodeGroup basis -->
          <info:schedulingPolicy>failrshare</info:schedulingPolicy> <!-- ComputingShare.SchedulingPolicy -->
          <info:OSFamily>linux</info:OSFamily> <!-- can also be specified on a per-nodeGroup basis -->
          <info:OSName>centos</info:OSName> <!-- can also be specified on a per-nodeGroup basis -->
          <info:OSVersion>4.2</info:OSVersion> <!-- can also be specified on a per-nodeGroup basis -->

          <!-- for publication in legacy infosys -->
          <info:clusterOwner>University of NeverLand</info:clusterOwner>
          <info:clusterLocation>DK-2100</info:clusterLocation>
          <info:clusterSupport>support@cluster.org</info:clusterSupport>
          <info:opSys>Linux-2.6.9-34.EL</info:opSys>
          <info:opSys>glibc-2.3.4</info:opSys>
          <info:middleware>acme-1.0</info:middleware>
          <info:localSE>gsiftp://my.storage/data2/</info:localSE>
          <info:interactiveContactstring>gsissh://frontend.cluster:2200</info:interactiveContactstring>
          <!-- end legacy options -->

          <!-- a group of identical nodes -->
          <!-- published as ExecutionEnvironment -->
          <info:nodeGroup name="dualcore">

              <!-- options for selecting the nodes that belong into this nodeGroup -->
              <!-- not needed for homogeneous queues -->
              <info:nodeSelection>
                  <info:regex>^compute-2-[0-9]*</info:regex> <!-- INI tag: nodeSelectionRegex-->
                  <info:regex>^node-2-[0-9]*</info:regex>
                  <info:command>/local/scripts/listnodes.sh quad</info:command> <!-- INI tag: nodeSelectionCommand-->
                  <info:LRMSToken>rack2</info:LRMSToken> <!-- INI tag: nodeSelectionLRMSToken-->
              </info:nodeSelection>

              <info:totalInstances>32</info:totalInstances> <!-- override autodetected value -->
              <info:architecture>amd64</info:architecture>
              <info:physicalCPUs>1</info:physicalCPUs>
              <info:logicalCPUs>2</info:logicalCPUs>
              <info:CPUVendor>AuthenticAMD</info:CPUVendor>
              <info:CPUModel>Athlon 64 Dual Core 5000+</info:CPUModel>
              <info:CPUVersion>2</info:CPUVersion>
              <info:CPUClockSpeed>2600</info:CPUClockSpeed>
              <info:CPUTimeScalingFactor>1.4</info:CPUTimeScalingFactor>
              <info:WallTimeScalingFactor>1.4</info:WallTimeScalingFactor>
              <info:mainMemorySize>2048</info:mainMemorySize>
              <info:virtualMemorySize>40000</info:virtualMemorySize>
              <info:OSFamily>linux</info:OSFamily>
              <info:OSName>centos</info:OSName>
              <info:OSVersion>5.1</info:OSVersion>
              <info:virtualMachine>false</info:virtualMachine>
              <info:networkInfo>100mbitethernet</info:networkInfo>
              <info:benchmark>specfp2000 333</info:benchmark>
              <info:benchmark>cfp2006 1200</info:benchmark>
          </info:nodeGroup>

          <info:nodeGroup name="doublequadcore">
              <info:architecture>amd64</info:architecture>
              <info:physicalCPUs>2</info:physicalCPUs>
              <info:logicalCPUs>8</info:logicalCPUs>
              <info:CPUVendor>GenuineIntel</info:CPUVendor>
              <info:CPUModel>E7340</info:CPUModel>
              <info:CPUVersion>11</info:CPUVersion>
              <info:CPUClockSpeed>2400</info:CPUClockSpeed>
              <info:CPUTimeScalingFactor>1</info:CPUTimeScalingFactor>
              <info:WallTimeScalingFactor>1</info:WallTimeScalingFactor>
              <info:mainMemorySize>8096</info:mainMemorySize>
              <info:virtualMemorySize>20000</info:virtualMemorySize>
              <info:benchmark>specint2000 944</info:benchmark>
              <info:benchmark>cint2006 1300</info:benchmark>
          </info:nodeGroup>

          <!-- published as ComputingShare -->
          <info:clusterShare name="knowarc">
              <info:description>Condor pool charged.uio.no - for PGS</info:description>
              <info:nodeGroupName>dualcore</info:nodeGroupName>
              <info:authorizedVO>knowarc.org</info:authorizedVO>
              <info:authorizedVO>nordugrid.org</info:authorizedVO>
              <info:maxVirtualMemory>2000</info:maxVirtualMemory>
              <info:maxSlotsPerJob>8</info:maxSlotsPerJob>
              <info:preemption>false</info:preemption>
              <lrms:queue>knowarc</lrms:queue>
              <lrms:ll_class>knowarc</lrms:ll_class>
              <lrms:slurm_partition>knowarc</lrms:slurm_partition>
              <lrms:slurm_project>knowarc</lrms:slurm_project>
              <lrms:fork_job_limit>cpunumber</lrms:fork_job_limit>
              <lrms:queue_node_string>gridlong_nodes</lrms:queue_node_string>
              <lrms:sge_jobopts>-P atlas -r yes</lrms:sge_jobopts>
              <lrms:condor_requirements>Memory&gt;=1000 &amp;&amp; (Arch == "INTEL" || Arch == "x86_64")
 || (Arch == "x86_64")</lrms:condor_requirements>
              <lrms:lsf_architecture>ia64</lrms:lsf_architecture>
          </info:clusterShare>

          <info:clusterShare name="atlas">
              <info:description>Condor pool charged.uio.no - test of Atlas VO</info:description>
              <info:nodeGroupName>doublequadcore</info:nodeGroupName>
              <info:nodeGroupName>dualcore</info:nodeGroupName>
              <info:authorizedVO>ATLAS/no</info:authorizedVO>
              <info:authorizedVO>ATLAS/Role=production</info:authorizedVO>
              <info:maxSlotsPerJob>1</info:maxSlotsPerJob>
              <info:preemption>true</info:preemption>
          </info:clusterShare>
      </info:infoProvider>
    </Service>
  </Chain>
</ArcConfig>


\documentclass{book}
%\documentclass{article}           %for shorter notes
\usepackage{graphicx}              %for PNG images (pdflatex)
%\usepackage{graphics}              %for EPS images (latex)
\usepackage[linkbordercolor={1.0 1.0 0.0}]{hyperref}  %for \url tag
\usepackage{color}                 %for defining custom colors
\usepackage{framed}                %for shaded and framed paragraphs
\usepackage{textcomp}              %for various symbols, e.g. Registered Mark
\usepackage{geometry}              %for defining page size
\usepackage{longtable}             %for breaking tables
%
\geometry{verbose,a4paper,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2cm}
\hypersetup{
  pdfauthor = {Mattias Ellert, Bjarte Mohn, Ivan Marton, Gabor Roczei},
  pdftitle = {libarcclient},
  pdfsubject = {A Client Library for ARC},
  pdfkeywords = {ARC,client,library},
  pdfcreator = {PDFLaTeX with hyperref package},
  pdfproducer = {PDFLaTeX}
}
%
\bibliographystyle{IEEEtran}       %a nice bibliography style
%
\def\efill{\hfill\nopagebreak}%
\hyphenation{Nordu-Grid}
\setlength{\parindent}{0cm}
\setlength{\FrameRule}{1pt}
\setlength{\FrameSep}{8pt}
\addtolength{\parskip}{5pt}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\renewcommand{\arraystretch}{1.3}
\newcommand{\dothis}{\colorbox{shadecolor}}
\newcommand{\globus}{Globus Toolkit\textsuperscript{\textregistered}~2~}
\newcommand{\GT}{Globus Toolkit\textsuperscript{\textregistered}}
\newcommand{\ngdl}{\url{http://ftp.nordugrid.org/download}~}
\newcommand{\arclib}{libarcclient}
\newcommand{\ACC}{\texttt{ACC}}
\newcommand{\ACCConfig}{\texttt{ACCConfig}}
\newcommand{\Broker}{\texttt{Broker}}
\newcommand{\ClientInterface}{\texttt{ClientInterface}}
\newcommand{\ClientTCP}{\texttt{ClientTCP}}
\newcommand{\ClientHTTP}{\texttt{ClientHTTP}}
\newcommand{\ClientSOAP}{\texttt{ClientSOAP}}
\newcommand{\ExecutionTarget}{\texttt{ExecutionTarget}}
\newcommand{\Job}{\texttt{Job}}
\newcommand{\JobController}{\texttt{JobController}}
\newcommand{\JobDescription}{\texttt{JobDescription}}
\newcommand{\JobSupervisor}{\texttt{JobSupervisor}}
\newcommand{\Loader}{\texttt{Loader}}
\newcommand{\Logger}{\texttt{Logger}}
\newcommand{\TargetGenerator}{\texttt{TargetGenerator}}
\newcommand{\TargetRetriever}{\texttt{TargetRetriever}}
\newcommand{\Submitter}{\texttt{Submitter}}
\newcommand{\URL}{\texttt{URL}}
\newcommand{\UserConfig}{\texttt{UserConfig}}
\newcommand{\XML}{\texttt{XML}}
\newcommand{\XMLNode}{\texttt{XMLNode}}
\definecolor{shadecolor}{rgb}{1,1,0.6}
\definecolor{salmon}{rgb}{1,0.9,1}
\definecolor{bordeaux}{rgb}{0.75,0.,0.}
\definecolor{cyan}{rgb}{0,1,1}
%
%----- DON'T CHANGE HEADER MATTER
\begin{document}
\def\today{\number\day/\number\month/\number\year}

\begin{titlepage}

\begin{tabular}{rl}
\resizebox*{3cm}{!}{\includegraphics{ng-logo.png}}
&\parbox[b]{2cm}{\textbf \it {\hspace*{-1.5cm}NORDUGRID\vspace*{0.5cm}}}
\end{tabular}

\hrulefill

%-------- Change this to NORDUGRID-XXXXXXX-NN

{\raggedleft NORDUGRID-TECH-20\par}

{\raggedleft \today\par}

\vspace*{2cm}

%%%%---- The title ----
{\centering \textsc{\Large {\arclib}}\Large \par}
\vspace*{0.5cm}
    
%%%%---- A subtitle, if necessary ----
{\centering \textit{\large A Client Library for ARC}\large \par}
    
\vspace*{1.5cm}
%%%%---- A list of authors ----
{\centering \large Mattias Ellert\footnote{mattias.ellert@fysast.uu.se} \large \par}
{\centering \large Iv\'{a}n M\'{a}rton\footnote{martoni@niif.hu} \large \par}
{\centering \large Bjarte Mohn\footnote{bjarte.mohn@fysast.uu.se} \large \par}
{\centering \large G\'{a}bor R\H{o}czei\footnote{roczei@niif.hu} \large \par}
%%%%---- An abstract - if style is article ----
%\begin{abstract}
%The abstract
%\end{abstract}
\end{titlepage}

\tableofcontents                   %Comment if use article style
\newpage
\chapter{Preface}
\label{sec:intro}

This document describes from a technical viewpoint a plugin based
client library for the new Web Service (WS) based Advanced Resource
Connector~\cite{arc} (ARC) middleware. The library consists of a set
of C++ classes for

\begin{itemize}
\item{handling proxy, user and host certificates,}
\item{performing resource discovery and information retrieval,}
\item{job submission and management and}
\item{data handling.}
\end{itemize}

All capabilities are enabled for three different grid flavours
(Production ARC, ARC1 and gLite~\cite{glite}) through a modular design
using plugins specialized for each supported middleware. Future
extensions to support additional middlewares involve plugin
compilation only i.e.\ no recompilation of main libraries or clients
is necessary.

Using the library, a set of command line tools have been built which
puts the library's functionality at the fingertips of users. While
this documentation will illustrate how such command line tools can be
built, the main documentation of the command line tools is given in
the client user manual~\cite{ui}.

In the following we will give a functionality overview in
Section~\ref{sec:FuncOver} while all technical details will be given
in Section~\ref{sec:Implementation}. Section~\ref{sec:cli} will
through examples show how command line interfaces can be built upon
the library.

\chapter{Functionality Overview}
\label{sec:FuncOver}

The new {\arclib} makes extensive use of plugins for command
handling. These plugins are handled by a set of higher level classes
which thus are the ones to offer the plugin functionality to external
calls. In this section an overview of the library's main functionality
is given which also introduces the most important higher level
classes.

\section{Resource Discovery and Information Retrieval}
\label{sec:TargetDiscovery}

With the increasing number of grid clusters around the world, a
reliable and fast resource discovery and information retrieval
capability is of crucial importance for a user interface. The new
{\arclib} resource discovery and information retrieval component
consists of three classes; the {\TargetGenerator}, the
{\TargetRetriever} and the {\ExecutionTarget}. Of these the
{\TargetRetriever} is a base class for further grid middleware
specific specialization (plugin).

Figure \ref{fig:ResDisc} depicts how the classes work together in a
command chain to discover all resources registered with a certain
information server. Below a description of each step is given:

\begin{figure}[ht]
\centering{{\scalebox{0.75}{\includegraphics{TargetDiscovery.png}}}
\caption{\label{fig:ResDisc}Diagram depicting the resource discovery
  and information retrieval process}}
\end{figure}

\begin{enumerate}
\item{The {\TargetGenerator} takes three arguments as input. The first
  argument is a reference to a {\UserConfig} object containing a
  representation of the contents of the user's configuration file. The
  second and third arguments contain lists of strings. The first list
  contains individually selected and rejected computing services,
  while the second list contains individually selected and rejected
  index servers. Rejected servers and services are identified by that
  its name is prefixed by a minus sign in the lists. The name of the
  servers and services should be given either in the form of an alias
  defined in the {\UserConfig} object or as the name of its grid
  flavour followed by a colon and the URL of its information contact
  endpoint.}
\item{These lists are parsed through alias resolution before being
  used to initialize the complete list of selected and rejected
  {\URL}s pointing to computing services and index servers.}
\item{For each selected index server and computing service a
  {\TargetRetriever} plugin for the server's or service's grid flavour
  is loaded using the ARC loader. The {\TargetRetriever} is
  initialized with its {\URL} and the information about whether it
  represents a computing service or an index server.}
\item{An external call is received calling for targets to be
  prepared. The call for targets is processed by each
  {\TargetRetriever} in parallel.}
\item{A {\TargetRetriever} representing an index server first tries to
  register at the index server store kept by the {\TargetGenerator}.
  If allowed to register, the index server is queried and the query
  result processed. The {\TargetGenerator} will not allow
  registrations from index servers present in its list of rejected
  index servers or from servers that have already registered
  once. Index servers often register at more than one index server,
  thus different {\TargetRetriever}s may discover the same server.}
\item{If while processing the query result the {\TargetRetriever}
  finds an other registered index server or a registered computing
  service it creates a new {\TargetRetriever} for the found server or
  service and forwards the call for targets to the new
  {\TargetRetriever}.}
\item{A {\TargetGenerator} representing a computing service first
  tries to register at the service store kept by the
  {\TargetGenerator}. If allowed to register, the computing server is
  queried and the query result processed. The {\TargetGenerator} will
  not allow registrations from computing services present in its list
  of rejected computing services or from service that have already
  registered once. Computing services often register at more than one
  index server, thus different {\TargetRetriever}s may discover the
  same service.}
\item{When processing the query result the {\TargetRetriever} will
  create an {\ExecutionTarget} for each queue found on the computing
  service and collect all possible information about them. It will
  then store the {\ExecutionTarget} in the found targets store kept
  by the {\TargetGenerator} for later usage (e.g.\ status printing or
  job submission).}
\end{enumerate}

\section{Job Submission}
\label{sec:JobSubmission}

Job submission starts with the resource discovery and target
preparation as outlined in the Section~\ref{sec:TargetDiscovery}. Not
until a list of possible targets (which allows the user) is available
is the job description read in order to enable bulk job submission of
widely different jobs without having to reperform the resource
discovery. In addition to the classes mentioned above the job
submission makes use of the {\Broker}, {\JobDescription} and
{\Submitter} classes.  The {\Submitter} is base class for further grid
middleware specific specialization (plugin) similarly to the {\TargetRetriever}.

\begin{figure}[ht]
\centering{{\scalebox{0.75}{\includegraphics{JobSubmission.png}}}
\caption{\label{fig:JobSub}Diagram depicting the submission of a job
  to a computing service.}}
\end{figure}

Figure \ref{fig:JobSub} shows a job submission sequence and below a
description of each step is given:

\begin{enumerate}
\item{The {\TargetGenerator} has prepared a list of
  {\ExecutionTarget}s. Depending on the {\URL}s provided to the
  {\TargetGenerator} the list of found {\ExecutionTarget}s may be
  empty or contain several targets. Targets may even represent more
  than one grid flavour. The list of found targets are given as input
  to the {\Broker}.}
\item{In order to rank the found services ({\ExecutionTarget}s) the
  {\Broker} needs detailed knowledge about the job requirements, thus
  the {\JobDescription} is passed as input to the brokering process.}
\item{The {\Broker} outputs a ordered list of {\ExecutionTarget}s
  according to the provided {\JobDescription}.}
\item{Each {\ExecutionTarget} has a method to return a specialized
  {\Submitter} which is capable of submitting jobs to the service it
  represents. The best suitable {\ExecutionTarget} for the job is
  asked to return a {\Submitter} for job submission.}
\item{The {\Submitter} takes the {\JobDescription} as input and
  uploads it to the computing service.}
\item{The {\Submitter} identifies local input files from the
  {\JobDescription} and uploads them to the computing service.}
\end{enumerate}

\section{Job Management}

Once a job is submitted job related information (job identification
string, cluster etc) is stored in a local XML file which hosts similar
information for all active jobs. This file may contain jobs running on
completely different grid flavours, and thus job management should be
handled using plugins similar to resource discovery and job
submission. The job managing plugin is called the {\JobController} and
it is supported by the {\JobSupervisor} and {\Job} classes.

\begin{figure}[ht]
\centering{{\scalebox{0.75}{\includegraphics{JobManagement.png}}}
\caption{\label{fig:JobMan}Diagram depicting how job controlling
  plugins, {\JobController}s, are loaded and initialized.}}
\end{figure}

Figure~\ref{fig:JobMan} shows how the three different classes work
together and below a step by step description is given:

\begin{enumerate}
\item{The {\JobSupervisor} takes four arguments as input. The first
  argument is a reference to a {\UserConfig} object containing a
  representation of the contents of the user's configuration file. The
  second is a list of strings containing job identifiers and job
  names, the third is a list of strings of clusters to select or
  reject (in the same format as described for the {\TargetGenerator}
  above). The last argument is the name of the file containing the
  local information about active jobs, hereafter called the joblist
  file.}
\item{A job identifier does not uniquely define which grid flavour
  runs a certain job. Thus this information is stored in the joblist
  file upon submission by the {\Submitter} and the joblist file is
  extensively used by the {\JobSupervisor} to identify the
  {\JobController} flavours which are to be loaded. The information in
  the joblist file is also used to look up the job identifier for jobs
  specified using job names. Alias resolution for the selected and
  rejected clusters are performed using the information in the
  {\UserConfig} object.}
\item{Suitable {\JobController}s are loaded}
\item{The list of job identifiers and selected and rejected clusters
  are passed to each {\JobController} which uses the information to
  fill its internal \texttt{JobStore}.}
\item{Residing within the {\JobSupervisor} the {\JobController}s are
  now accessible for external calls (i.e. job handling).}
\end{enumerate}

\chapter{Implementation}
\label{sec:Implementation}

In this section an overview of all important classes in the new
{\arclib} is given. The overview is subdivided in two parts where
first all the generic classes are presented,
Section~\ref{sec:genclass}, before the grid flavour specializations
are presented in Section~\ref{sec:plugins}. Classes are described both
in words and by code.

\section{Generic Classes}
\label{sec:genclass}

\subsection{{\ACC}}

The Arc Client Component ({\ACC}) class is a base class needed for the
{\Loader} in order to create loadable classes. It stores information
about which flavour it supports and security related information
needed by all ACC specializations.

\begin{shaded}
\begin{verbatim}
class ACC {
protected:
  ACC(Config *cfg, const std::string& flavour);
public:
  virtual ~ACC();
  const std::string& Flavour();
protected:
  std::string flavour;
  std::string proxyPath;
  std::string certificatePath;
  std::string keyPath;
  std::string caCertificatesDir;
};
\end{verbatim}
\end{shaded}

\subsection{{\TargetGenerator}}

The {\TargetGenerator} class is the main class for resource discovery
and information retrieval. It loads {\TargetRetriever} plugins in
accordance with the input {\URL}s using the ARC {\Loader}~\cite{hed}
(e.g.\ if an {\URL} pointing to an ARC1 resource is given the
TargetRetrieverARC1 is loaded).

To perform a resource discovery, first construct a {\TargetGenerator}
object using the {\TargetGenerator} constructor,

\begin{shaded}
\begin{verbatim}
TargetGenerator(const UserConfig& usercfg,
                const std::list<std::string>& clusters,
                const std::list<std::string>& indexurls);
\end{verbatim}
\end{shaded}

where \texttt{clusters} and \texttt{indexurls} are lists of strings
where each string is either the name of a grid flavour followed by a
colon and the URL of an information contact endpoint for a computing
service or index server, respectively, of that grid flavour or an
alias defined in the {\UserConfig} object passed as the first
argument, e.g.:

\begin{shaded}
\begin{small}
\begin{verbatim}
ARC0:ldap://grid.tsl.uu.se:2135/Mds-Vo-name=Sweden,o=grid
ARC0:ldap://grid.tsl.uu.se:2135/nordugrid-cluster-name=grid.tsl.uu.se,Mds-Vo-name=local,o=grid
\end{verbatim}
\end{small}
\end{shaded}

where the former is the URL to an index server while the latter is an
URL to a computing service. If a string in \texttt{clusters} or
\texttt{indexurls} is prefixed by a minus sign, the corresponding
computing service or index server is rejected and excluded during
resource discovery.

To prepare a list of {\ExecutionTarget}s use the {\TargetGenerator}
object and invoke its method

\begin{shaded}
\begin{verbatim}
GetTargets(int targetType, int detailLevel);
\end{verbatim}
\end{shaded}

The {\TargetGenerator} will pass this request to the loaded
{\TargetRetriever}s running them as individual threads for improved
performance. The {\TargetGenerator} keeps records of index servers and
computing services found by the {\TargetRetriever}s in order to avoid
multiple identical queries. Accepted {\ExecutionTarget}s are stored in
the FoundTargets array kept by the {\TargetGenerator}. See also
Section~\ref{sec:TargetDiscovery} for a schematic drawing of the
resource discovery process.

Information about the found {\ExecutionTarget}s can be printed by 

\begin{shaded}
\begin{verbatim}
PrintTargetInfo(bool longlist) const;
\end{verbatim}
\end{shaded}

\subsection{{\TargetRetriever}}

The {\TargetRetriever} is base class for {\TargetRetriever} grid
middleware specializations and inherits from the {\ACC} base class in
order to be loadable by the ARC \texttt{Loader}. It is designed to
work in conjunction with the {\TargetGenerator} and contains the pure
virtual method

\begin{shaded}
\begin{verbatim}
virtual void GetTargets(TargetGenerator& mom, int targetType,
                        int detailLevel) = 0;
\end{verbatim}
\end{shaded}

which is to be implemented by the specialized class. While it is not
mandatory it is recommended that the specialized class divides this
method into two components: QueryIndex and InterrogateTarget. The
former handles index server queries, and the latter the computing
service queries and {\ExecutionTarget} preparation.

If an index server query yields a URL to a different index server
than the one queried, then the {\TargetRetriever} should call itself
recursively creating a new {\TargetRetriever} for the discovered index
server.

\subsection{{\ExecutionTarget}}

The {\ExecutionTarget} is the class representation of a computing
resource (queue) capable of executing a grid job. It serves as input
to the {\Broker} which is foreseen to be able to select between
different {\ExecutionTarget}s from different grid flavours without a
priori knowing their difference. The {\ExecutionTarget} class mimics
the Glue2 information model (with a flattened structure), and thus a
mapping between attributes from other information systems into the
Glue2 format is needed. Appendix \ref{app:ExTarget} shows the current
mapping for the production ARC, ARC1 and gLite middlewares.

All attributes of the {\ExecutionTarget} can be printed by the method

\begin{shaded}
\begin{verbatim}
void Print(bool longlist) const;
\end{verbatim}
\end{shaded}

Following a broker decision jobs are to be submitted. Since all
information about the selected computing service resides within the
selected {\ExecutionTarget}, the {\ExecutionTarget} is capable of
returning a {\Submitter} capable of submitting a job to the service it
represents.

\begin{shaded}
\begin{verbatim}
Submitter *GetSubmitter(const UserConfig& ucfg) const;
\end{verbatim}
\end{shaded}

The {\UserConfig} object is used to configure the security related
information needed by the {\Submitter}.

\subsection{{\Broker}}

The Broker inherits from the {\ACC} base class in order to be loadable by the ARC \texttt{Loader}. It is the base class of the specialized Brokers. If you are using the arcsub command then you can choose a broker type with ``-b`` parameter. There is a solution for add parameters to these descendants Brokers. Here is an example:

\begin{shaded}
\begin{verbatim}
arcsub -b RandomBroker:a,b,c -c ARC1:https://knowarc1.grid.niif.hu:60000/arex job.jsdl
\end{verbatim}
\end{shaded}

The Broker's constructor set the PreFilteringDone and the TargetSortingDone values to false because we need to call at first the PreFilterTargets and second the GetBestTarget which trigger the specialised Broker sorting method.

The base Broker operations are the followings:


\begin{enumerate}
\item{The first step is the PreFilterTargets, this implements the matchmaking: the JobDescription and the TargetGenerator's ExecutionTargets will be compared inside this method. JobDescription content the job's JobInnerRepresentation, and the ExecutionTarget content the candidate cluster's queue information. There are main elements in the JobInnerRepresentation which are used for matchmaking, these are documented in this Appendix: \ref{sec:broker-mapping}, every matchmaking elements and their comparison logic are there. The macthmaking working on this way: it takes every JobInnerrepresentation elements which are relevant and in an ordered way check them. If a matchmaking element is not presented in the JobInnerRepresentation then it will be ignored, but if it is there than the ExecutionTarget should content its pair.} For example SessionLifeTime is in the JobInnerRepresentaion and the WorkingAreaLifeTime is in the ExecutionTarget (these are matchmaking pair). If the WorkingAreaLifeTime is not defined then the Broker cannot check the times therefore it will ignore this cluster, but if the WorkingAreaLifeTime exist and the comparison between this elements are true then this check will be passed other way the cluster will be ignored. We are using this rule for every elements checking. There is only one exception and this is the ProcessingStartTime because if the DownTime is not defined in the ExecutionTarget than we can trust by it that the job can anytime start and it will be not killed with shutdown. This rule checking runs for every ExecutionTargets and if every matchmaking checks are ok for a target then this ExecutionTarget will be added to the PossibleTargets vector.
\item{If the matchmaking finished then  the PreFilteringDone variable will be true and the TargetSortingDone will be false. }
\item{The next step is the GetBestTarget method calling, this will give an ExecutionTarget which is good for our job. If the Possibletarget vector empty then it will give nothing. The first time the GetBestTarget will trigger the specialid Broker type sorting with this method calling:  SortTargets. This SortTargets method is virtual method, therefore every specialised Broker should implement it.}
\item{If the SortTargets finished then the TargetSortingDone will be true and the GetBestTarget will return the first element of the PossibleTargetVector and the current iterator will be incremented with one.}
\item{If the submision failed to this cluster then we can call again the GetBestTarget and we will get an other ExecutionTarget till it will not consume. If  the targets run out from the PossibleTargetVector then the GetBestTarget's bool parameter will be true, its name is EndOfList''}
\end{enumerate}

\begin{shaded}
\begin{verbatim}
class Broker : public ACC {
public:
    ExecutionTarget& GetBestTarget(bool &EndOfList);
    void PreFilterTargets(Arc::TargetGenerator& targen, Arc::JobDescription jd);    
protected:
    Broker(Config *cfg);
    virtual ~Broker();
    virtual void SortTargets() = 0;
    std::vector<Arc::ExecutionTarget> PossibleTargets;
    bool TargetSortingDone;
    Arc::JobInnerRepresentation jir;
    static Logger logger;
private:
    std::vector<Arc::ExecutionTarget>::iterator current;
    bool PreFilteringDone;
};
\end{verbatim}
\end{shaded}

The Broker class content  two useful data elements: logger and JobInnerRepresentation. These can be helpful when somebody create a specialised Broker and he would like to use the logger and need some information about the job.


\subsection{{\JobDescription}}

When addressing interoperability it is of paramount importance to
transparently address grid job descriptions written in different job
description languages by translating them automatically. In the
{\arclib} library this functionality is implemented in the
{\JobDescription} class. The inner representation (\texttt{JobInnerRepresentation}
class) is similar to the GIN-JSDL and all elements correspond to
variables. These variables are either simple variables or complex data structures,
and are private in the {\JobDescription} class.


This is a generic class that takes a job
description (string) as input

\begin{shaded}
\begin{verbatim}
bool setSource(const std::string source);
\end{verbatim}
\end{shaded}

in any supported formats (currently XRSL~\cite{xrsl}, JDL~\cite{jdl},
JSDL~\cite{jsdl}), converts and stores it in a GIN-JSDL-like internal job
description format. The identification of the source description
format is internally handled by a \texttt{JobDescriptionOrderer} class
which identifies the format by pattern matching. If the source string is
empty or the \texttt{JobDescriptionOrderer} class can not be recognized
to any formats, then it does not store anything and returns with false, otherwise
it converts and stores it. 

Different operations, like getting the job description in other
formats or getting job-related information, can be performed by using the
description-independent functions of this class, e.g.:

\begin{shaded}
\begin{verbatim}
bool getProduct(std::string& product, std::string format = "POSIXJSDL")
\end{verbatim}
\end{shaded}

The {\JobDescription} class has three back-end classes, sometimes
referred to as back-end or translator modules, corresponding to the
three supported job description languages. The {\JobDescription} class
chooses the appropriate back-end module according to the pattern matching
performed by the \texttt{JobDescriptionOrderer}, and uses the back-end
module for parsing and generating the job descriptions.
If the inner representation is empty or the source job descrition is not
valid, then the output is empty too and returns with false.
When the source format is the same as the output format and it is not XRSL,
than we set the product string to the source string. The XRSL output is
always generated from the inner representation. 

Parsing is currently possible from any of the languages. JSDL, XRSL and
JDL output generation is implemented already but even for these there are
some limitations.

The conversion mainly means a syntactical transformation and the
{\JobDescription} class can do nothing in those cases where
there are not enough data is available to assemble a given attribute or
when information can be lost because the received attribute has no
equivalent in the output language.

For the JSDL output generation the {\JobDescription} class uses
the core JSDL's capabilities amended with the JSDL-POSIX and JSDL-ARC
extensions. The loss of information is minimal in case of generating
such an output.

For the JDL generation the latest version of JDL specification was
used (v0.9) \cite{jdl}. Deprecated and backward compatibility
attributes are not implemented.


\subsection{{\Submitter}}

{\Submitter} is base class for grid specific specializations (plugin).
It submits job(s) to the service it represents and uploads (by the job
needed) local input files.

\begin{shaded}
\begin{verbatim}
virtual bool Submit(JobDescription& jobdesc, XMLNode& info) = 0;
\end{verbatim}
\end{shaded}

The \texttt{Submit} method fills the {\XMLNode} \texttt{info} with all
needed information about the job for later job management. The
{\Submitter} is returned by the {\ExecutionTarget} selected for job
execution and thus the {\ExecutionTarget} populates (through its
{\XMLNode} config element) the {\Submitter} with information about
submission endpoint ({\URL}) and job description languages understood
by the target.

\subsection{{\JobSupervisor}}

The {\JobSupervisor} is responsible for loading the appropriate
{\JobController}s for managing jobs running on a certain grid
flavour. Job manipulation can be performed either on individual jobs
or on groups of jobs (e.g.\ all jobs running on certain cluster or all
jobs with job state ``FINISHED''), and in order to translate the
information given by the user into a set of loadable {\JobController}s
the {\JobSupervisor} makes extensive use of the local joblist file
housing information about all active jobs. Thus the {\JobSupervisor}
constructor becomes

\begin{shaded}
\begin{verbatim}
JobSupervisor(const UserConfig& usercfg,
              const std::list<std::string>& jobs,
              const std::list<std::string>& clusters,
              const std::string& joblist);
\end{verbatim}
\end{shaded}

where \texttt{jobs} is a list of job identifiers and job names,
\texttt{clusters} is a list of selected and rejected computing
services in the same format as described above for the
{\TargetGenerator}, \texttt{joblist} is a string containing the name
of the joblist file.

Although being loaded by the {\JobSupervisor} the {\JobController}
objects truly resides within the ARC {\Loader} which is a member of
the {\JobSupervisor} class. In order to get handles on the
{\JobController}s the inline method

\begin{shaded}
\begin{verbatim}
const std::list<Arc::JobController*>& GetJobControllers();
\end{verbatim}
\end{shaded}

returns a list of pointers to the loaded {\JobController}s.

\subsection{{\JobController}}

The {\JobController} is a base class for grid specific
specializations, but also the implementer of all public functionality
offered by the {\JobController}s. In other words all virtual functions
of the {\JobController} are private. The initialization of a
(specialized) {\JobController} object takes two steps. First the
{\JobController} specialization for the required grid flavour must be
loaded by the ARC {\Loader}, which sees to that the {\JobController}
receives information about its flavour (grid) and the local joblist
file containing information about all active jobs (flavour
independent). Next step is the filling of the {\JobController}'s job
pool \texttt{JobStore} which is the pool of jobs that the
{\JobController} can manage.

\begin{shaded}
\begin{verbatim}
void FillJobStore(const std::list<URL>& jobids,
                  const std::list<URL>& clusterselect,
                  const std::list<URL>& cluterreject);
\end{verbatim}
\end{shaded}

Here \texttt{jobids}, \texttt{clusterselect} and
\texttt{clusterreject} have been resolved for job names and aliases by
the {\JobSupervisor}, and no further resolution is needed. The
following rules are observed when filling the \texttt{JobStore}:

\begin{enumerate}
\item{If the \texttt{jobids} list has entries, fill \texttt{JobStore}
  with the by user requested jobs.}
\item{If the \texttt{clusterselect} list has entries, fill
  \texttt{JobStore} with the jobs running on the selected clusters.}
\item{If clusters are rejected and \texttt{JobStore} has entries,
  remove from \texttt{JobStore} all jobs running on rejected
  clusters.}
\item{If \texttt{jobs} and \texttt{clusterselect} are both empty
  lists, fill \texttt{JobStore} with all jobs except those running on
  possible rejected clusters.}
\end{enumerate}

The steps above completes the initialization of the {\JobController}
which is now ready for handling jobs. The public functions of the
{\JobController} offer to get (download), clean, cancel, etc one or
more jobs and uses the private specializations for issuing the
command. Here exemplified by the \texttt{Stat} command:

\begin{shaded}
\begin{small}
\begin{verbatim}
bool JobController::Stat(const std::list<std::string>& status,
                         const bool longlist,
                         const int timeout) {

  GetJobInformation();

  for (std::list<Job>::iterator it = jobstore.begin();
       it != jobstore.end(); it++) {
    if (it->State.empty()) {
      logger.msg(WARNING, "Job state information not found: %s",
                 it->JobID.str());
      Time now;
      if (now - it->LocalSubmissionTime < 90)
        logger.msg(WARNING, "This job was very recently "
                   "submitted and might not yet"
                   "have reached the information-system");
      continue;
    }
    it->Print(longlist);
  }
  return true;
}
\end{verbatim}
\end{small}
\end{shaded}

The \texttt{Stat} command prints the job information to screen and in
order to do so the {\JobController} has to query local information
server for the latest status. Due to different protocols used for
different grid flavours (e.g.\ ldap for production ARC), the
\texttt{GetJobInformation} has to be grid flavour specific and is only
declared as a private virtual method within the {\JobController} base
class. For details about the flavour specific implementations see
Section~\ref{sec:plugins}.

\subsection{{\Job}}

The {\Job} is a generic job class for storing all job related
information. Attributes are derived from the Glue2 information model
and thus a mapping is needed for non Glue2 compliant grid middlewares.
Appendix \ref{app:job} shows the present mapping schema.

All attributes of the {\Job} can be printed by the method

\begin{shaded}
\begin{verbatim}
void Print(bool longlist) const;
\end{verbatim}
\end{shaded}

\subsection{{\UserConfig}}

The {\UserConfig} class handles the client setup i.e. proxy,
certificate and key location, user and system configuration and local
joblist location. Upon initialization (constructor) the {\UserConfig}
locates the user files

\begin{shaded}
\begin{verbatim}
$HOME/.arc/client.xml
$HOME/.arc/jobs.xml
\end{verbatim}
\end{shaded}

and if either of them is non-existing a default (empty) one is created.

The {\UserConfig} has three main public methods

\begin{shaded}
\begin{verbatim}
const std::string& JobListFile() const;
const XMLNode& ConfTree() const;
bool ApplySecurity(XMLNode& ccfg) const;
\end{verbatim}
\end{shaded}

where \texttt{JobListFile()} returns the string pointing to the
jobs.xml file while \texttt{ConfTree()} returns a configuration
{\XMLNode} object which is the merge between the user and system
configurations. In order to do this the method has to locate the
system configuration and resolve possible conflicts with the user
configuration. This proceeds through the following chain of actions:

\begin{enumerate}
\item{Try reading system configuration from \texttt{<ARC Install
    Location>/etc/arcclient.xml}}
\item{If the previous step failed try reading system configuration
  from \texttt{/etc/arcclient.xml}}
\item{Merge system and user configuration by adding all system
  configuration not already listed in the user configuration to the
  latter.}
\end{enumerate}

The \texttt{ApplySecurity(XMLNode\& ccfg)} adds security tags to the
ccfg {\XMLNode} as follows:

\begin{itemize}
\item{If the \texttt{\$X509\_USER\_PROXY} environment variable is set,
  use its value to define a \texttt{ProxyPath} tag in \texttt{cfg}. If
  the file does not exist or can't be read exit with an error.}
\item{Otherwise, if the \texttt{\$X509\_USER\_CERT} environment
  variable is set, use its value and the value of the
  \texttt{\$X509\_USER\_KEY} environment variable to define
  \texttt{CertificatePath} and \texttt{KeyPath} tags in \texttt{cfg}.
  If \texttt{\$X509\_USER\_KEY} is not set or either file does not
  exist or can't be read exit with an error.}
\item{Otherwise, if the merged user configuration tree (see
  \texttt{ConfTree} contains a \texttt{ProxyPath} tag, copy it to
  \texttt{cfg}. If the file does not exist or can't be read exit with
  an error.}
\item{Otherwise, if the merged user configuration tree contains a
  \texttt{CertificatePath} tag, copy it to \texttt{cfg} along with the
  accompanying \texttt{KeyPath} tag. If the \texttt{KeyPath} tag is
  undefined or either file does not exist or can't be read exit with
  an error.}
\item{Otherwise, if the file \texttt{/tmp/x509up\_u + userid} exists
  add a \texttt{ProxyPath} tag in \texttt{cfg} pointing to it.}
\item{Otherwise, add \texttt{CertificatePath} and \texttt{KeyPath}
  tags to \texttt{cfg} pointing to
  \texttt{\$HOME/.globus/usercert.pem} and
  \texttt{\$HOME/.globus/userkey.pem}, respectively. If either file
  does not exist exit with error.}
\item{If the \texttt{\$X509\_CERT\_DIR} environment variable is set,
  use its value to define a \texttt{CACertificatesDir} tag in
  \texttt{cfg}. If the directory does not exist, exit with an error.}
\item{Otherwise, if the user ID is not zero and the directory
  \texttt{\$HOME/.globus/certificates} exists add a
  \texttt{CACertificatesDir} tag in \texttt{cfg} pointing to it.}
\item{Otherwise, add a \texttt{CACertificatesDir} tag in \texttt{cfg}
  pointing to \texttt{/etc/grid-security/certificates}. If the
  directory does not exist, exit with an error.}
\end{itemize}

\subsection{{\ACCConfig}}

Locating Arc Client Components (plugins) is handled by the
{\ACCConfig} class. It inherits from \texttt{BaseConfig} and
implements only one method

\begin{shaded}
\begin{verbatim}
virtual XMLNode MakeConfig(XMLNode cfg) const;
\end{verbatim}
\end{shaded}

The \texttt{MakeConfig} method searches plugin paths for all libraries
named \texttt{libacc*}. Matching libraries are added as plugins to the
configuration object \texttt{cfg}.

\subsection{{\ClientInterface}}

The {\ClientInterface} class is a utility base class used for
configuring a client side Message Chain Component (MCC) chain and
loading it into memory. It has several specializations of increasing
complexity of the MCC chains.

\subsubsection{{\ClientTCP}}

The {\ClientTCP} class is a specialization of the {\ClientInterface}
which sets up a client MCC chain for TCP communication, and optionally
with a TLS layer on top.

\subsubsection{{\ClientHTTP}}

The {\ClientHTTP} class inherits from the {\ClientTCP} class and adds
an HTTP MCC to the chain.

\subsubsection{{\ClientSOAP}}

The {\ClientSOAP} class inherits from the {\ClientHTTP} class and adds
a SOAP MCC to the chain. Specializations of the {\TargetRetriever},
{\Submitter} and {\JobController} classes that communicate with SOAP
based services make use of this class.

\section{Specialized Classes (Grid Flavour and Broker plugins)}
\label{sec:plugins}

\subsection{ARC0 Plugins}

The ARC0 plugins enables support for the interfaces used by computing
elements running ARC version 0.x.

The ARC 0.x local information system uses the {\GT}~\cite{globus} GRIS
with a purpose made ARC schema. The information index server used is the
{\GT} GIIS. Both these servers are using the LDAP~\cite{ldap}
protocol. The specialization of the {\TargetRetriever} class for ARC0
is implemented using the ARC LDAP Data Management Component (DMC) (see
\cite{hed} for technical details).

Jobs running on an ARC 0.x computing element are handled by the ARC
grid-manager~\cite{gm}. Job submission and job control are done using
the gridftp~\cite{gridftp} protocol. The specializations of the
{\Submitter} and {\JobController} classes use the globus ftp control
library.

Stage-in and stage-out of input and output files are also done using
the gridftp~\cite{gridftp} protocol. This means that proper
functionality of the ARC0 plugins requires the gridftp DMC.

\subsection{ARC1 Plugins}

The computing element in ARC version 1.x is the A-Rex~\cite{arex}
service running in a HED~\cite{hed} container.

A-Rex implements the BES~\cite{ogsa-bes} standard interface. Since
this is a SOAP~\cite{soap} based interface the specializations of the
{\TargetRetriever}, {\Submitter} and {\JobController} classes make use
of a chain of ARC Message Chain Components (MCC~\cite{hed}) ending
with the SOAP client MCC.

The A-Rex service uses the https protocol put and get methods for
stage-in and stage-out of input and output files. Therefore, the ARC1
plugins requires the http DMC.

\subsection{gLite Plugins}

The gLite computing element offers several interfaces, one of them
being the Web Service based computing element interface known as the
CREAM CE~\cite{cream}. The current revision of this interface (CREAM
version 2) has been chosen for implementation within {\arclib} for the
following reasons:

\begin{itemize}
\item CREAM2 has a Web Service interface that fits the Web Service
  based ARC.
\item CREAM2 enables direct access to the gLite computing element
  without having to go via the gLite workload management system.
\item CREAM2 contains numerous improvements when compared to the
  earlier CREAM versions.
\item CREAM2 supports direct job status queries.
\item CREAM2 offers a convenient way of handling input and output
  files through accessing the input and output sandbox via GridFTP.
\end{itemize}

gLite resources are registered in top level and site BDIIs. The CREAM
specialization of the {\TargetRetriever} therefore makes use of the
LDAP DMC similarly to the ARC0 plugins.

CREAM has its own SOAP based interface. The CREAM
specializations of the {\Submitter} and {\JobController} classes
therefore use an MCC chain ending with the SOAP client MCC the same 
way the ARC1 plugin does.

Stage-in and stage-out of input and output files are done using the
gridftp protocol. The gridftp DMC is therefore required.

\subsection{Broker plugins}

\subsubsection{RandomBroker}

The ExecutionTarget sorting based on randomization, the only thing is what happen is that the PossibTargets vector will be shuffled.

\subsubsection{FastestCPUBroker}

The sorting method based on the fastest CPU, we are using for this the CINT2006 (Integer Component of SPEC CPU2006) benchmark solution, here are more information about this benchmark type: http://www.spec.org/cpu2006/CINT2006/

These is the sorting algorithm for this Broker:

\begin{enumerate}
\item{There is a cluster filtering at the begining of the sorting. If the cluster is not publish the specint2006 benchmark information then it will be ignored.}
\item{That cluster will be the first in the PossibleTargets vector which has the highest specint2006 value.}
\end{enumerate}

\subsubsection{FastestQueueBroker}

The sorting method based on the shortest queue, where the waiting jobs number is the lowest. 

These is the sorting algorithm for this Broker:

\begin{enumerate}
\item{That clusters will be removed which are not content the target sorting information: WaitingJobs, TotalSlots and FreeSlots.}
\item{Sort the targets according to the number of waiting jobs (in percent of the cluster size). That cluster will be better where the WaitingJobs number division with the TotalSlots give lower number. This solution will result that the scale queue will be independent from the cluster size.}
\item{If several clusters(queues) have free slots (CPUs) do basic load balancing}
\end{enumerate}

\subsubsection{DataBroker}

The main idea was that the jobs should submit to that cluster where the data is. The sorting method based on the A-REX file cache checking. There is a CacheCheck interface inside the A-REX which can be use to query that files present or not in the cache directory. There is a limitation at the current state because the CacheCheck interface can use only this cache directory format: 

\begin{shaded}
\begin{verbatim}
cachedir="/tmp/cache"
\end{verbatim}
\end{shaded}

If the cachedir parameter content {\%}U or other substitute element then the CacheCheck will not working.

These is the sorting algorithm for this Broker:

\begin{enumerate}
\item{Only the A-REX service has CacheCheck method therefore the other clusters will be ignored}
\item{The files URL collected from the JobInnerRepresentation }
\item{Every ExecutionTargets which are A-REXs will be called its  CacheCheck method, there is only one query per service, with this it will be not increment its load too. The Broker will summarize the file sizes. The CacheMappingTable is an array where the A-REX's URL is the key and the summarized file size is the value. When there is some problem to query file size from the A-REX then the summarized size will be zero.}
\item{The last step is to sort the PossibleTargets vector in descending way  (CacheMappingTable used for this), which cluster content the most data that will be at the front of the vector.}
\end{enumerate}

Example for CacheCheck request what can be sent to an A-REX service:

\begin{shaded}
\begin{verbatim}
<CacheCheck>
   <TheseFilesNeedToCheck>
       <FileURL>http://knowarc1.grid.niif.hu/storage/Makefile</FileURL>
       <FileURL>ftp://download.nordugrid.org/test/README</FileURL>
   </TheseFilesNeedToCheck>
</CacheCheck>
\end{verbatim}
\end{shaded}

Example CacheCheck response of the A-REX service:

\begin{shaded}
\begin{verbatim}
<CacheCheckResponse>
   <CacheCheckResult>
   <Result>
         <FileURL>http://knowarc1.grid.niif.hu/storage/Makefile</FileURL>
         <ExistInTheCache>true</ExistInTheCache>
         <FileSize>30</FileSize>
   </Result>
   <Result>
         <FileURL>http://knowarc1.grid.niif.hu/storage/Makefile</FileURL>
         <ExistInTheCache>true</ExistInTheCache>
         <FileSize>30</FileSize>
   </Result>
  </CacheCheckResult>
</CacheCheckResponse>
\end{verbatim}
\end{shaded}

   
   
\subsubsection{PythonBroker}

This broker allows users to write their customized broker in
python. To use this broker the user should write a python class. The
class should contain:

\begin{itemize}

\item{an \_\_init\_\_ method that takes a Config object as input, and}
\item{a SortTargets method that takes a python list of ExecutionTarget
  objects and a JobInnerRepresentation object as input.}

\end{itemize}

The Config, ExecutionTarget and JobInnerRepresentation classes are
available in the swig generated arc python module.

To invoke the python broker, the name of the python module defining
the broker class and the name of the broker class must be given. If
e.g. the broker class MyBroker is defined in the python module
SampleBroker the command line option to arcsub to use this broker is:

\begin{shaded}
\begin{verbatim}
-b PythonBroker:SampleBroker.MyBroker
\end{verbatim}
\end{shaded}

Additional arguments to the python broker can be added by appending
them after an additional colon after the python class name:

\begin{shaded}
\begin{verbatim}
-b PythonBroker:SampleBroker.MyBroker:args
\end{verbatim}
\end{shaded}

Extracting these additional arguments should be done in the python
broker class's \_\_init\_\_ method.

For a complete example of a simple python broker see the
SampleBroker.py file that comes with your arc python installation.

\chapter{Building Command Line Interfaces}
\label{sec:cli}

Given all components listed above it is possible to write versatile
command line interfaces (cli) for grid job submission and
management. {\arclib} offers the following native commands:

\begin{enumerate}
\item{\texttt{arcstat} - for computing resource or grid job status
  queries.}
\item{\texttt{arcsub} - for grid job submission}
\item{\texttt{arcget} - for downloading output of finished, cancelled
  or failed grid jobs.}
\item{\texttt{arckill} - for terminating grid jobs.}
\item{\texttt{arcclean} - for removing a grid job's session directory
  including all contents}
\item{\texttt{arccat} - for performing the \texttt{cat} command to a
  running grid job's std out or std error file.}
\end{enumerate}

Each of the commands above are encoded within one C++ file with the
following structure, here exemplified with the arcget command:

\begin{shaded}
\begin{verbatim}
#ifdef HAVE_CONFIG_H
#include <config.h>
#endif

#include <iostream>
#include <list>
#include <string>

#include <arc/ArcLocation.h>
#include <arc/IString.h>
#include <arc/Logger.h>
#include <arc/OptionParser.h>
#include <arc/client/JobController.h>
#include <arc/client/JobSupervisor.h>
#include <arc/client/UserConfig.h>

int main(int argc, char **argv) {

  setlocale(LC_ALL, "");

  Arc::Logger logger(Arc::Logger::getRootLogger(), "arcget");
  Arc::LogStream logcerr(std::cerr);
  Arc::Logger::getRootLogger().addDestination(logcerr);
  Arc::Logger::getRootLogger().setThreshold(Arc::WARNING);

  Arc::ArcLocation::Init(argv[0]);

  Arc::OptionParser options(istring("[job ...]"),
                            istring("The arcget command is used for "
                                    "retrieving the results from a job."),
                            istring("Argument to -c has the format "
                                    "Flavour:URL e.g.\n"
                                    "ARC0:ldap://grid.tsl.uu.se:2135/"
                                    "nordugrid-cluster-name=grid.tsl.uu.se,"
                                    "Mds-Vo-name=local,o=grid"));

  bool all = false;
  options.AddOption('a', "all",
                    istring("all jobs"),
                    all);

  // Removed most of the option definition from this write-up to
  // save space. See the real source file for the complete list.
  // ...

  bool version = false;
  options.AddOption('v', "version", istring("print version information"),
                    version);

  std::list<std::string> jobs = options.Parse(argc, argv);

  if (!debug.empty())
    Arc::Logger::getRootLogger().setThreshold(Arc::string_to_level(debug));

  Arc::UserConfig usercfg(conffile);
  if (!usercfg) {
    logger.msg(Arc::ERROR, "Failed configuration initialization");
    return 1;
  }

  if (debug.empty() && usercfg.ConfTree()["Debug"]) {
    debug = (std::string)usercfg.ConfTree()["Debug"];
    Arc::Logger::getRootLogger().setThreshold(Arc::string_to_level(debug));
  }

  if (version) {
    std::cout << Arc::IString("%s version %s", "arcget", VERSION)
              << std::endl;
    return 0;
  }

  if (jobs.empty() && joblist.empty() && !all) {
    logger.msg(Arc::ERROR, "No jobs given");
    return 1;
  }

  if (joblist.empty())
    joblist = usercfg.JobListFile();

  Arc::JobSupervisor jobmaster(usercfg, jobs, clusters, joblist);

  std::list<Arc::JobController*> jobcont = jobmaster.GetJobControllers();

  if (jobcont.empty()) {
    logger.msg(Arc::ERROR, "No job controllers loaded");
    return 1;
  }

  int retval = 0;
  for (std::list<Arc::JobController*>::iterator it = jobcont.begin();
       it != jobcont.end(); it++)
    if (!(*it)->Get(status, downloaddir, keep, timeout))
      retval = 1;

  return retval;
}
\end{verbatim}
\end{shaded}

\appendix

\chapter{{\ExecutionTarget}}
\label{app:ExTarget}

\section{Domain and Location attributes}

\subsection*{std::string DomainName}

ARC0: nordugrid-cluster-name \\
CREAM: GlueSiteName

\subsection*{std::string Owner}

ARC0: nordugrid-cluster-owner

\subsection*{std::string Address}

\subsection*{std::string Place}

CREAM: GlueSiteLocation

\subsection*{std::string PostCode}

ARC0: nordugrid-cluster-location

\subsection*{float Latitude}

CREAM: GlueSiteLatitude

\subsection*{float Longitude}

CREAM: GlueSiteLongitude

\section{ComputingService and ComputingEndpoint attributes}

\subsection*{std::string CEID}

\subsection*{std::string CEName}

\subsection*{std::string Capability}

\subsection*{std::string Type}

\subsection*{std::string QualityLevel}

\subsection*{URL url}

ARC0: nordugrid-cluster-contactstring \\
CREAM: GlueCEInfoContactString

\subsection*{std::string Technology}

\subsection*{std::string Interface}

ARC0: ``GridFTP''

\subsection*{std::string InterfaceExtension}

\subsection*{std::string SupportedProfile}

\subsection*{std::string Implementor}

ARC0: ``NorduGrid''

\subsection*{std::string ImplementationName}

ARC0: ``ARC0'' \\
CREAM: GlueCEImplementationName

\subsection*{std::string ImplementationVersion}

ARC0: nordugrid-cluster-middleware \\
CREAM: GlueCEImplementaionVersion

\subsection*{std::string HealthState}

ARC0: nordugrid-queue-status

\subsection*{std::string ServingState}

CREAM: GlueCEStateStatus (GlueVOView $||$ GlueCE)

\subsection*{std::string IssuerCA}

ARC0: nordugrid-cluster-issuerca (nordugrid-cluster-issuerca-hash)

\subsection*{std::list<std::string> TrustedCA}

ARC0: nordugrid-cluster-trustedca

\subsection*{Time DowntimeStarts}

\subsection*{Time DowntimeEnds}

\subsection*{std::string Staging}

ARC0: nordugrid-cluster-nodeaccess

\subsection*{std::string Jobdescription}

\section{ComputingService and ComputingShare load attributes}

\subsection*{int TotalJobs}

ARC0: nordugrid-cluster-totaljobs \\
CREAM: GlueCEStateTotalJobs (GlueVOView $||$ GlueCE)

\subsection*{int RunningJobs}

ARC0: nordugrid-queue-running \\
CREAM: GlueCEStateRunningJobs (GlueVOView $||$ GlueCE)

\subsection*{int WaitingJobs}

ARC0: nordugrid-queue-queued $||$ nordugrid-cluster-queuedjobs \\
CREAM: GlueCEStateWaitingJobs (GlueVOView $||$ GlueCE)

\subsection*{int StagingJobs}

\subsection*{int SuspendedJobs}

\subsection*{int PreLRMSWaitingJobs}

ARC0: nordugrid-queue-prelrmsqueued

\subsection*{int LocalRunningJobs}

ARC0: nordugrid-queue-running $-$ nordugrid-queue-gridrunning

\subsection*{int LocalWaitingJobs}

ARC0: nordugrid-queue-queued $-$ nordugrid-queue-gridqueue

\subsection*{int FreeSlots}

CREAM: GlueCEStateFreeJobSlots $||$ GlueCEStateFreeCPUs (GlueVOView $||$ GlueCE)

\subsection*{std::string FreeSlotsWithDuration}

\subsection*{int UsedSlots}

ARC0: nordugrid-queue-usedcpus

\subsection*{int RequestedSlots}

\section{ComputingShare attributes}

\subsection*{std::string MappingQueue}

ARC0: nordugrid-queue-name

\subsection*{Period MaxWallTime}

ARC0: nordugrid-queue-maxwalltime \\
CREAM: GlueCEPolicyMaxWallClockTime (GlueVOView $||$ GlueCE)

\subsection*{Period MaxTotalWallTime}

\subsection*{Period MinWallTime}

ARC0: nordugrid-queue-minwalltime

\subsection*{Period DefaultWallTime}

ARC0: nordugrid-queue-defaultwalltime

\subsection*{Period MaxCPUTime}

ARC0: nordugrid-queue-maxcputime \\
CREAM: GlueCEPolicyMaxCPUTime (GlueVOView $||$ GlueCE)

\subsection*{Period MaxTotalCPUTime}

\subsection*{Period MinCPUTime}

ARC0: nordugrid-queue-defaultcputime

\subsection*{Period DefaultCPUTime}

ARC0: nordugrid-queue-defaultcputime

\subsection*{int MaxTotalJobs}

CREAM: GlueCEPolicyMaxTotalJobs (GlueVOView $||$ GlueCE)

\subsection*{int MaxRunningJobs}

ARC0: nordugrid-queue-maxrunning \\
CREAM: GlueCEPolicyMaxRunningJobs (GlueVOView $||$ GlueCE)

\subsection*{int MaxWaitingJobs}

ARC0: nordugrid-queue-maxqueable \\
CREAM: GlueCEPolicyMaxWaitingJobs (GlueVOView $||$ GlueCE)

\subsection*{int NodeMemory}

ARC0: nordugrid-queue-nodememory $||$ nordugrid-cluster-nodememory \\
CREAM: GlueHostMainMemoryRAMSize

\subsection*{int MaxPreLRMSWaitingJobs}

\subsection*{int MaxUserRunningJobs}

ARC0: nordugrid-queue-maxuserrun \\
CREAM: GlueCEPolicyAssignedJobSlots (GlueVOView $||$ GlueCE) % ??

\subsection*{int MaxSlotsPerJob}

CREAM: GlueCEPolicyMaxSlotsPerJob (GlueVOView $||$ GlueCE)

\subsection*{int MaxStageInStreams}
\subsection*{int MaxStageOutStreams}
\subsection*{std::string SchedulingPolicy}

ARC0: nordugrid-queue-schedulingpolicy

\subsection*{int MaxMemory}

ARC0: nordugrid-queue-nodememory $||$ nordugrid-cluster-nodememory \\
CREAM: GlueHostMainMemoryVirtualSize

\subsection*{int MaxDiskSpace}
\subsection*{URL DefaultStorageService}

ARC0: nordugrid-cluster-localse \\
CREAM: GlueCEInfoDefaultSE (GlueVOView $||$ GlueCE)

\subsection*{bool Preemption}

CREAM: GlueCEPolicyPreemption (GlueVOView $||$ GlueCE)

\subsection*{Period EstimatedAverageWaitingTime}

CREAM: GlueCEStateEstimatedResponseTime (GlueVOView $||$ GlueCE)

\subsection*{Period EstimatedWorstWaitingTime}

CREAM: GlueCEStateWorstResponseTime (GlueVOView $||$ GlueCE)

\subsection*{std::string ReservationPolicy}

\section{ComputingManager attributes}

\subsection*{std::string ManagerType}

ARC0: nordugrid-cluster-lrms-type (nordugrid-cluster-lrms-version)

\subsection*{bool Reservation}
\subsection*{bool BulkSubmission}
\subsection*{int TotalPhysicalCPUs}

ARC0: nordugrid-queue-totalcpus $||$ nordugrid-cluster-totalcpus

\subsection*{int TotalLogicalCPUs}

ARC0: nordugrid-queue-totalcpus $||$ nordugrid-cluster-totalcpus

\subsection*{int TotalSlots}

ARC0: nordugrid-queue-totalcpus $||$ nordugrid-cluster-totalcpus

\subsection*{bool Homogeneity}

ARC0: nordugrid-queue-homogeneity $||$ nordugrid-cluster-homogeneity

\subsection*{std::string NetworkInfo}

\subsection*{bool WorkingAreaShared}

\subsection*{int WorkingAreaFree}

ARC0: nordugrid-cluster-sessiondir-free

\subsection*{Period WorkingAreaLifeTime}

ARC0: nordugrid-cluster-sessiondir-lifetime

\subsection*{int CacheFree}

ARC0: nordugrid-cluster-cache-free

\section{ExecutionEnvironment attributes}

\subsection*{std::string Platform}

ARC0: nordugrid-queue-architecture $||$ nordugrid-cluster-architecture

\subsection*{bool VirtualMachine}

\subsection*{std::string CPUVendor}

ARC0: nordugrid-queue-nodecpu $||$ nordugrid-cluster-nodecpu

\subsection*{std::string CPUModel}

ARC0: nordugrid-queue-nodecpu $||$ nordugrid-cluster-nodecpu

\subsection*{std::string CPUVersion}

ARC0: nordugrid-queue-nodecpu $||$ nordugrid-cluster-nodecpu

\subsection*{int CPUClockSpeed}

\subsection*{int MainMemorySize}

\subsection*{std::string OSFamily}

ARC0: nordugrid-queue-opsys $||$ nordugrid-cluster-opsys

\subsection*{std::string OSName}

ARC0: nordugrid-queue-opsys $||$ nordugrid-cluster-opsys

\subsection*{std::string OSVersion}

\subsection*{bool ConnectivityIn}

\subsection*{bool ConnectivityOut}

\subsection*{std::list<Benchmark> Benchmarks}

ARC0: nordugrid-queue-benchmark $||$ nordugrid-cluster-benchmark

\section{ApplicationEnvironment}

\subsection*{std::list<ApplicationEnvironment> ApplicationEnvironments}

ARC0: nordugrid-cluster-runtimeenvironment \\
CREAM: GlueHostApplicationSoftwareRunTimeEnvironment

\chapter{{\Job}}
\label{app:job}

\section{Information stored in the job list file}

\subsection*{std::string Flavour}

\subsection*{URL JobID}

\subsection*{URL Cluster}

\subsection*{URL SubmissionEndpoint}

\subsection*{URL InfoEndpoint}

\subsection*{URL ISB}

\subsection*{URL OSB}

\subsection*{URL AuxURL}

\subsection*{std::string AuxInfo}

\section{Information retrieved from the informtaion system}

\subsection*{std::string Name}

ARC0: nordugrid-job-jobname

\subsection*{std::string Type}

\subsection*{URL IDFromEndpoint}

\subsection*{std::string LocalIdFromManager}

\subsection*{std::string JobDescription}

\subsection*{std::string State}

ARC0: nordugrid-job-status

\subsection*{std::string RestartState}

ARC0: nordugrid-job-rerunable

\subsection*{int ExitCode}

ARC0: nordugrid-job-exitcode

\subsection*{std::string ComputingManagerExitCode}

\subsection*{std::list<std::string> Error}

ARC0: nordugrid-job-errors

\subsection*{int WaitingPosition}

ARC0: nordugrid-job-queuerank

\subsection*{std::string UserDomain}

\subsection*{std::string Owner}

ARC0: nordugrid-job-globalowner

\subsection*{std::string LocalOwner}

\subsection*{Period RequestedWallTime}

ARC0: nordugrid-job-reqwalltime

\subsection*{Period RequestedTotalCPUTime}

ARC0: nordugrid-job-reqcputime

\subsection*{int RequestedMainMemory}

\subsection*{int RequestedSlots}

\subsection*{std::string StdIn}

ARC0: nordugrid-job-stdin

\subsection*{std::string StdOut}

ARC0: nordugrid-job-stdout

\subsection*{std::string StdErr}

ARC0: nordugrid-job-stderr

\subsection*{std::string LogDir}

ARC0: nordugrid-job-gmlog

\subsection*{std::list<std::string> ExecutionNode}

Arc0: nordugrid-job-executionnodes

\subsection*{std::string ExecutionCE}

ARC0: nordugrid-job-execcluster

\subsection*{std::string Queue}

ARC0: nordugrid-job-execqueue

\subsection*{Period UsedWallTime}

ARC0: nordugrid-job-usedwalltime

\subsection*{Period UsedTotalCPUTime}

ARC0: nordugrid-job-usedcputime

\subsection*{int UsedMainMemory}

ARC0: nordugrid-job-usedmem

\subsection*{std::list<std::string> UsedApplicationEnvironment}

ARC0: nordugrid-job-runtimeenvironment

\subsection*{int UsedSlots}

ARC0: nordugrid-job-cpucount

\subsection*{Time LocalSubmissionTime}

\subsection*{Time SubmissionTime}

ARC0: nordugrid-job-submissiontime

\subsection*{Time ComputingManagerSubmissionTime}

\subsection*{Time StartTime}

\subsection*{Time ComputingManagerEndTime}

\subsection*{Time EndTime}

ARC0: nordugrid-job-completiontime

\subsection*{Time WorkingAreaEraseTime}

ARC0: nordugrid-job-sessiondirerasetime

\subsection*{Time ProxyExpirationTime}

ARC0: nordugrid-job-proxyexpirationtime

\subsection*{std::string SubmissionHost}

ARC0: nordugrid-job-submissionui

\subsection*{std::string SubmissionClientName}

ARC0: nordugrid-job-clientsoftware

\subsection*{Time CreationTime}

ARC0: Mds-validfrom

\subsection*{Period Validity}

ARC0: Mds-validto $-$ Mds-validfrom

\subsection*{std::string OtherMessages}

ARC0: nordugrid-job-comment

\section{Associations}

\subsection*{URL JobManagementEndpoint}

\subsection*{URL DataStagingEndpoint}

\section{ExecutionEnvironment (condensed)}

\subsection*{bool VirtualMachine}

\subsection*{std::string UsedCPUType}

\subsection*{std::string UsedOSFamily}

\subsection*{std::string UsedPlatform}

\chapter{{\Broker}}
\label{app:broker}

\section{Broker mapping}
\label{sec:broker-mapping}

http://svn.nordugrid.org/trac/nordugrid/browser/arc1/trunk/doc/client/broker-mapping.ods

\section{JobInnerrepresentation}
\label{sec:jobinnerrepresentation}

http://svn.nordugrid.org/trac/nordugrid/browser/arc1/trunk/doc/client/JobInnerRepresentation.ods

\bibliography{grid}

\end{document}

%% LyX 1.4.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[twoside,english]{article}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2cm}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{amsmath}
\usepackage{amssymb}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{graphicx}                              %for PNG images (pdflatex)
%\usepackage{graphics}                              %for EPS images (latex)
\usepackage[linkbordercolor={1.0 1.0 0.0}]{hyperref} %for \url tag
\usepackage{color}                                 %for defining custom colors
\usepackage{framed}                                %for shaded and framed paragraphs
\usepackage{textcomp}                              %for various symbols, e.g. Registered Mark
\usepackage{geometry}                              %for defining page size
\usepackage{longtable}                             %for breaking tables
%
\geometry{verbose,a4paper,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2cm}
\hypersetup{
  pdfauthor = {C.U.Soettrup},
  pdftitle ={Arc backend infrastructure},
  pdfsubject = {Description and developer guide},
  pdfkeywords = {ARC,NorduGrid,manual,Backend,LRMS, Infosystem},
  pdfcreator = {PDFLaTeX with hyperref package},
  pdfproducer = {PDFLaTeX}
}
%
\bibliographystyle{IEEEtran}                       %a nice bibliography style
%
\def\efill{\hfill\nopagebreak}%
\hyphenation{Nordu-Grid}
\setlength{\parindent}{0cm}
\setlength{\FrameRule}{1pt}
\setlength{\FrameSep}{8pt}
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\renewcommand{\arraystretch}{1.3}
\newcommand{\dothis}{\colorbox{shadecolor}}
\newcommand{\globus}{Globus Toolkit\textsuperscript{\textregistered}~2~}
\newcommand{\GT}{Globus Toolkit\textsuperscript{\textregistered}}
\newcommand{\ngdl}{\url{http://ftp.nordugrid.org/download}~}
\definecolor{shadecolor}{rgb}{1,1,0.6}
\definecolor{salmon}{rgb}{1,0.9,1}
\definecolor{bordeaux}{rgb}{0.75,0.,0.}
\definecolor{cyan}{rgb}{0,1,1}
%

\usepackage{babel}
\makeatother
\begin{document}
\def\today{\number\day/\number\month/\number\year}



\begin{titlepage}



\begin{tabular}{rl}\resizebox*{3cm}{!}{\includegraphics[width=3cm,height=2cm]{ng-logo.png}} &\parbox[b]{2cm}{\textbf \it {\hspace*{-1.5cm}NORDUGRID\vspace*{0.5cm}}} \end{tabular}



\hrulefill

{\raggedleft NORDUGRID-TECH-13\par}



{\raggedleft \today\par}



\vspace*{2cm}

\begin{center}
\textsc{\Large Arc batch system back-end interface guide with support for GLUE 2}
\par\end{center}{\Large \par}

\vspace*{0.5cm}

\begin{center}
\textit{\large Description and developer's guide}
\par\end{center}{\large \par}

\vspace*{1.5cm}

{\centering \large Adrian Taga\footnote{v.a.taga@fys.uio.no}, Thomas Frågåt\footnote{thomasf@fys.uio.no}, C.U.Søttrup, Bal\'azs K\'onya, G\'abor R\H oczei \par}

\end{titlepage}

\thispagestyle{empty}

$ $

\newpage

\tableofcontents{}

\newpage


\section{Introduction\label{sec:intro}}

This document describes the Advanced Resource Connector\cite{ARC}
batch system back-end infrastrucure. It aims to describe the infrastructure
in enough detail that a developer can add a new local resource management
system (LRMS) to the ARC middleware. It also intends to serve as a
reference manual describing existing batch system interfaces. Note
that the current solution described in this manual is not a real interface,
it is too diffuse to be that.

The batch system back-ends are what tie the ARC grid middleware (through
the Grid Manager (GM\cite{GM}) and the Information System layer\cite{INFOSYS})
to the underlying cluster management system or LRMS. The back-ends
consist of set of shell and Perl scripts whose role are twofold: 

\begin{enumerate}
\item to allow the GM to manipulate jobs on the LRMS including job submit,
cancel operations and scanning for completed jobs
\item to collect information about jobs, users, batch system and the cluster
itself for the Information System. 
\end{enumerate}
The former will be referred to as the job control back-end interface
while the latter is the information system interface of the batch
system back-ends. These two will be treated separately in the following
sections. 

\subsection{ARC Classic}
As of ARC version 0.6 the the two sets of scripts are located in different
directories within the NorduGrid subversion tree\cite{subversion}.
The job control interface scripts can be found under \texttt{arc\_development\_line/grid-manager/LRMS/}
while the information collectors are located at \texttt{arc\_development\_line/infosystem/.}

Section 2, 3, and 4 gives a description of the classic ARC back-ends scripts.

\subsection{ARC1}
As of ARC version 0.9, which is to be the next generation ARC, the scripts are located in different directories within the NorduGrid subversion tree\cite{subversion} as well. 
The architecture of ARC1 is different from Classic ARC so the job control interface scripts can be found under
\texttt{arc1/trunk/src/services/a-rex/lrms/}
while the information collectors are located in \texttt{arc1/trunk/src/services/a-rex/infoproviders/}.

Furthermore, the next generation of ARC supports both the classic NorduGrid information schema\cite{INFOSYS} and
currently a minimal set of the GLUE specification version 2.0 schema\cite{GLUE2}.

The ARC1 back-end architecture and GLUE2 information model implementation is presented in Section 5.

\section{Job control interface}

Job control part of the LRMS interface is handled by the Grid Manager\cite{GM}.
It takes care of preparing a native batch system submission script,
managing the actual submission of the batch system job, cancellation
of job on request and scanning for completed batch jobs. Besides the
LRMS job control interface it is also the GM which provides e.g. the
data staging and communication with the grid client, provides RTE
environments, arranges file staging (to the node via LRMS capability),
dealing with stdout/stderr, etc. The job control batch system interface
of the GM requires three programs. These programs can be implemented
any way the designer sees fit, but all the existing back-end interfaces
use shell scripting for portability and ease of tailoring to a specific
site. The GM will call the following programs: cancel-LRMS-job, submit-LRMS-job,
and scan-LRMS-job. LRMS is replaced with the short hand name for the
LRMS e.g. cancel-pbs-job. The scripts are described one by one in
the following subsections. Useful information can also be found in
the Section \char`\"{}8.6 LRMS Support\char`\"{} and Section \char`\"{}8.7
Runtime Environment\char`\"{} of the Grid-Manager guide\cite{GM}. 


\subsection{Cancel-LRMS-job}

If a grid user cancels his job, the message will reach the grid-manager.
The manager will then call the cancel-LRMS-job for the suitable back-end.
The cancel script is called with a text file containing information
about the job. It is called the GRAMi file. It contains such information
as the original xRSL option and the job id in the local LRMS. Cancel-LRMS-job
must then use that information to find the job and remove it from
the queue or actually cancel it if it is running in the LRMS.


\subsection{Submit-LRMS-job}

The submit program is the most involved. It is called by the GM once
a new job arrives and needs to be submitted to the LRMS. Like cancel-LRMS-job
it is given the grami file as argument on execution. Submit-LRMS-job
then has to set up the session directories, run-time environment and
anything else needed. Then it should submit the job to the local LRMS.
This is normally done by generating a native job script for the LRMS
and then running the local submit command, but it could also be done
through an API if the LRMS supports it.


\subsection{Scan-LRMS-job}

Scan-LRMS-job is run periodically. Its job is to scan the LRMS for
jobs that have finished. Once it has found a finished job it should
write the exit-code of that job to the file job.\{gridid\}.lrms\_done
in the ARC jobstatus directory. Then it should call the gm-kick program
the GM will then notice that the job has finished and start finalizing
the job.

Generally two approaches are taken to find jobs that are done. One
is asking the LRMS. First all started grid jobs are found in the jobstatus
directory%
\footnote{normally /var/spool/nordugrid/jobstatus/, but can be set via the controldir
variable of arc.conf%
}. This can be done by checking if the status is INLRMS in the jobs
status file%
\footnote{job.\{gridid\}.status%
}. Then the LRMS is asked for the status of those jobs. If they are
done they are marked as such and the GM is activated. The problem
with this approach is that for most LRMSs the information about finished
jobs are only available for a short period after the job finished.
Therefore appropriate steps have to be taken if the job is known to
have been started but is no longer present in the LRMS. The normal
approach is to analyze the jobs status output in the session directory.

The second approach is to parse the LRMSs log files. This method has
some drawbacks e.g. the GM has to be allowed read access to the logs.
The back-end will then have to remember where in the log it was last
time it ran. This information will have to be stored in a file some
where on the front-end.


\subsection{Configuration parser}

Some of the back-ends will need information from the configuration
file. Since this functionality can be shared  among the back-ends,
a configuration file parser written in bash has been provided separately
for easy maintenance and extendability. 


\subsubsection{Functions}

\texttt{config\_parse\_file <config\_file>}

\begin{quote}
Parses a config file. It returns exit status 1 if the file cannot
be read, or 0 otherwise. Badly formed lines are silently ignored.
Option values can be surrounded by sigle quotes or double quotes.
Values without quotes are also accepted. Multi-valued options are
not supported currently. Only the last defined value is retained. 
\end{quote}
\texttt{config\_update\_from\_section <section\_name>}

\begin{quote}
Imports options from section <section\_name> of the config file into
environment variables of the form 'CONFIG\_optionname'. Already existing
environment variables are overwritten.
\end{quote}
Example:

\texttt{source \$ARC\_LOCATION/libexec/config\_parser.sh}

\texttt{config\_parse\_file /etc/arc.conf || exit 1}

\texttt{config\_update\_from\_section common}

\texttt{config\_update\_from\_section grid-manager}

\texttt{config\_update\_from\_section infosys}

\texttt{echo \$CONFIG\_pbs\_bin\_path }


\section{Information System interface}

The main purpose of the information system batch interface is to populate
the nordugrid information model with locally collected information
obtained from the batch system. Important to recall that the locally
collected information is broader than what the batch-system can offer,
information taken from the grid-layer (mostly grid manager), from
the front-end machine and from the \texttt{arc.conf} configuration
file are also needed and used to populate the nordugrid information
model\cite{INFOSYS}. Below only the batch system related information
collection is covered. Note that the separation of the different sources
is not always that straightforward (e.g. the grid-manager information
has some overlap with the batch system info). 

The information system interface consists of set of Perl scripts which
populate the local lDAP database by generating ldif files. Historically
two information provider \char`\"{}frameworks\char`\"{} have been
coexisted. As of ARC version 0.6 the old framework is being phased
out by the new framework. Briefly about the two frameworks:

\begin{itemize}
\item the old framework separated the non-batch system related functionality
into the \texttt{InfosysCluster.pm, InfosysQJU.pm} modules and kept
the batch system specific interface within the \texttt{cluster-condor.pl,
queue+jobs+users-condor.pl} (replace condor with your scheduler name)
files. There are two templates provided for batch system interface
developers: \texttt{cluster-gm.pl, queue+jobs+users-gm.pl}
\item the new framework originally proposed by Juha Lento%
\footnote{the original posting of the new framework proposal: http://staff.csc.fi/juha.lento/grid/rewrite.html%
} has been brought up-to-date by implementing all the features present
in the old framework. The new framework consists of two main scripts,
the \texttt{cluster.pl} and the \texttt{qju.pl}. The non-batch system
functionality is implemented by these script (plus some auxiliary
scripts). The batch system specific interface is moved to LRMS modules
such as \texttt{SGE.pm, PBS.pm, Fork.pm}, a template module \texttt{Template.pm}
is also provided. The main advantage of the new framework is the separation
of output generation from the information collection (this will ease
the migration to XML output).
\end{itemize}
The following subsection describes the LRMS interface part of the
information system as implemented via the new framework. To support
a particular LRMS a dedicated Perl module should be written that implements
the interface presented in the next subsections. Furthermore hooks
should be added to the \texttt{LRMS.pm} module, so that it uses the
correct Perl module depending on the LRMS type. Short description
of the files of the new framework:

\begin{itemize}
\item \texttt{cluster.pl and qju.pl}: main scripts called to populate the
nordugrid information model
\item \texttt{Shared.pm:} subroutines shared by cluster.pl and cluster.pl
\item \texttt{LogUtils.pm}: logging utilities
\item \texttt{LRMS.pm:} defines the LRMS interface (described in the next
subsection)
\item \texttt{Template.pm:} module template for implementing a new LRMS
interface
\item \texttt{SGE.pm, PBS.pm, LSF.pm, Fork.pm, LL.pm, Condor.pm}: actual
LRMS modules
\end{itemize}

\subsection{The LRMS Perl module interface}

The LRMS module should implement four functions as defined by the
\texttt{LRMS.pm}: \texttt{Cluster\_info}, that provides general information
about the local cluster, \texttt{Queue\_info}, that provides information
about a specified queue, \texttt{Jobs\_info} that gives information
about a list of specified jobs, and finally \texttt{user\_info} that
gives information about a grid user mapped to a local UNIX account.
All the functions are called with a hash containing the contents of
arc.conf.


\subsubsection{cluster\_info}

\texttt{Cluster\_info} is called only with the config hash. It should
then return an associative array with the following keys and the appropriate
value.

\begin{tabular}{|c|c|}
\hline 
key&
value\tabularnewline
\hline
\hline 
lrms\_type&
the type of LRMS e.g PBS\tabularnewline
\hline 
lrms\_version&
the version of the LRMS\tabularnewline
\hline 
totalcpus&
total number of CPUs in the cluster\tabularnewline
\hline 
queuedcpus&
total number of CPUs requested by LRMS queuing jobs (both grid and
non-grid)\tabularnewline
\hline 
usedcpus&
CPUs in the LRMS that are currently in use either by grid or non-grid
jobs\tabularnewline
\hline 
cpudistribution&
number of CPUs in a node and number of each type e.g. {}``8cpu:5
2cpu:100''\tabularnewline
\hline
\end{tabular}


\subsubsection{queue\_info}

In addition to the config \texttt{queue\_info} is called with the
name of the queue to get information on. The result should take the
following form.

\begin{tabular}{|c|c|}
\hline 
key&
value\tabularnewline
\hline
\hline 
status&
available slots in queue, negative number signals error\tabularnewline
\hline 
maxrunning&
limit on number of running jobs\tabularnewline
\hline 
maxqueuable&
limit on number of jobs queued on this queue\tabularnewline
\hline 
maxuserrun&
limit on number of running jobs per user\tabularnewline
\hline 
maxcputime&
limit on maximum CPU time for a job in this queue\tabularnewline
\hline 
mincputime&
limit on minimum CPU time for a job in this queue\tabularnewline
\hline 
defaultcput&
default CPU time limit for a job in this queue\tabularnewline
\hline 
maxwalltime&
limit on maximum wall time for a job in this queue\tabularnewline
\hline 
minwalltime&
limit on minimum wall time for a job in this queue\tabularnewline
\hline 
defaultwallt&
default wall time limit for a job in this queue\tabularnewline
\hline 
running&
number of CPUs used by running jobs (both grid and non-grid) in the
queue\tabularnewline
\hline 
queued&
CPUs requested by queuing jobs in the queue\tabularnewline
\hline 
totalcpus&
number of CPUs available to the queue\tabularnewline
\hline
\end{tabular}


\subsubsection{jobs\_info}

Like the rest the first argument is the config hash, then comes the
queue name and finally a list of job ids. Once again an associative
mapping should be made for each job. The key value pairs are:

\begin{tabular}{|c|c|}
\hline 
key&
value\tabularnewline
\hline
\hline 
status&
LRMS jobstatus mapping%
\footnote{LRMS job states mapping is described in\cite{INFOSYS} %
}:Running->'R', Queued->'Q', Suspended->'S', Exiting->'E', Other->'O'\tabularnewline
\hline 
rank&
the job's position in the LRMS queue\tabularnewline
\hline 
mem&
the memory usage of the job in kBs\tabularnewline
\hline 
walltime&
consumed wall-time in minutes\tabularnewline
\hline 
cputime&
consumed CPU-time in minutes\tabularnewline
\hline 
reqwalltime&
wall-time requested by job in minutes\tabularnewline
\hline 
reqcputime&
CPU-time requested by job in minutes\tabularnewline
\hline 
nodes&
list of execution hosts\tabularnewline
\hline 
comment&
array of string comments about the job in LRMS, can be an empty array\tabularnewline
\hline
\end{tabular}


\subsubsection{user\_info}

\texttt{Users\_info} is given the config hash, a queue name and a
list of local UNIX accounts (UIDs). It should then return an associative
array containing for each UID the number of free CPUs available for
that local account on the given queue and the number of queued jobs
on that queue.

\begin{tabular}{|c|c|}
\hline 
key&
value\tabularnewline
\hline
\hline 
freecpus&
number of freely available CPUs with their time limits in minutes
(see nordugrid-authuser-freecpus in\cite{INFOSYS})\tabularnewline
\hline 
queuelength&
estimated queue length for the specified user\tabularnewline
\hline
\end{tabular}


\section{Batch system specifics}

This section presents the batch system specific implementation details
including information on supported versions, constraints on batch
system configuration, known limitations, \texttt{arc.conf} parameters
and list of batch system features being utilized within the interface
are described.


\subsection{PBS}

The Portable Batch System (PBS) is one of the most popular batch systems.
PBS comes in many flavours such as OpenPBS (unsupported), Terascale
Open-Source Resource and QUEue Manager (TORQUE) and PBSPro (currently
owned by Altair Engineering). ARC supports all the flavours and versions
of PBS.


\subsubsection{Recommended batch system configuration}

PBS is a very powerful Local Resource Manager System with dozens of
configurable options. Server, queue and node attributes can be used
to configure the cluster's behaviour. In order to correctly interface
PBS to ARC (mainly the information provider scripts) there are a couple
of configuration REQUIREMENTS asked to be implemented by the local
system administrator:

\begin{enumerate}
\item The computing nodes MUST be declared as cluster nodes (job-exclusive),
at the moment time-shared nodes are not supported by the ARC setup.
If you intend to run more than one job on a single processor then
you can use the virtual processor feature of PBS. 
\item For each queue, you MUST set one of the max\_user\_run or max\_running
attributes and its value SHOULD BE IN AGREEMENT with the number of
available resources (i.e. don't set the max\_running = 10 if you have
only six (virtual) processors in your system). If you set both max\_running
and max\_user\_run then obviously max\_user\_run has to be less equal
than max\_running. 
\item For the time being, do NOT set server limits like max\_running, please
use queue-based limits instead. 
\item Avoid using the max\_load and the ideal\_load directives. The node's
mom config file (<PBS home on the node>/mom\_priv/config) should not
contain any max\_load or ideal\_load directives. PBS closes down a
node (no jobs are allocated to it) when the load on the node reaches
the max\_load value. The max\_load value is meant for controlling
time-shared nodes. In case of job-exclusive nodes there is no need
for setting these directives, moreover incorrectly set values can
close down your node. 
\item Routing queues are not supported, those can't be used within ARC.
\end{enumerate}
Additional useful configuration hints:

\begin{itemize}
\item If possible, please use queue-based attributes instead of server level
ones (for the time being, do not use server level attributes at all). 
\item You may use the \char`\"{}acl\_user\_enable = True\char`\"{} with
\char`\"{}acl\_users = user1,user2\char`\"{} attribute to enable user
access control for the queue. 
\item It is advisory to set the max\_queuable attribute in order to avoid
a painfully long dead queue. 
\item You can use node properties from the \texttt{<PBS home on the server>/server\_priv/nodes}
file together with the \texttt{resources\_default.neednodes} to assign
a queue to a certain type of node.
\end{itemize}
Checking your PBS configuration:

\begin{itemize}
\item The node definition can be checked by \texttt{<PBS installation path>/bin/pbsnodes
-a.} All the nodes MUST have ntype=cluster. 
\item The required queue attributes can be checked as \texttt{<PBS installation
path>/bin/qstat -f -Q queuename.} There MUST be a max\_user\_run or
a max\_running attribute listed with a REASONABLE value. 
\end{itemize}

\subsubsection{Relevant \texttt{arc.conf} options}

The ARC configuration manual contains detailed information on all
the ARC configuration parameters\cite{config}and should be consulted
as primary source. Below the PBS specific variables are collected.

\begin{itemize}
\item The PBS batch system back-end is enabled via setting the \texttt{lrms=\char`\"{}pbs\char`\"{}}
in the \texttt{{[}common]} configuration block. No need to specify
the flavour or the version number of the PBS, simply use the \texttt{{}``pbs''}
keyword as lrms configuration value.
\item \texttt{pbs\_bin\_path} configuration variable of the \texttt{{[}common]}
block should be set to the path to the qstat,pbsnodes,qmgr etc PBS
binaries.
\item \texttt{pbs\_log\_path} configuration variable of the \texttt{{[}common]}
block should be set to the path of the PBS server logfiles which are
used by the Grid-Manager to determine whether a PBS job is completed.
If not specified, the Grid-Manager will use the \texttt{qstat} command
to find completed jobs. 
\item \texttt{lrmsconfig} from the \texttt{{[}cluster]} block can be used
as an optional free text field to describe further details about the
PBS configuration (e.g. \texttt{lrmsconfig=\char`\"{}single job per
processor\char`\"{}}).
\item \texttt{dedicated\_node\_string} from the \texttt{{[}cluster]} block
specifies the string which is used in the PBS node config to distinguish
the grid nodes from the rest. Suppose only a subset of nodes are available
for grid jobs, and these nodes have a common \texttt{node property}
string, this case the \texttt{dedicated\_node\_string} should be set
to this value and only the nodes with the corresponding PBS \texttt{node
property} are counted as grid enabled nodes. Setting the \texttt{dedicated\_node\_string}
to the value of the PBS \texttt{node property} of the grid-enabled
nodes will influence how the totalcpus, user freecpus is calculated.
No need to set this attribute if the cluster is fully available for
the grid and the PBS configuration does not use the \texttt{node property}
method to assign certain nodes to grid queues.
\item \texttt{{[}queue/queuename]} block. For each grid-enabled (or grid
visible) PBS queue a corresponding \texttt{{[}queue]} block must be
defined. \texttt{queuename} should be the PBS queue name.
\item \texttt{scheduling\_policy} from the \texttt{{[}queue/queuename]}
block describes the scheduling policy of the queue. PBS by default
offers the FIFO scheduler, many sites run the MAUI. At the moment
\texttt{FIFO} \& \texttt{MAUI} are supported values. If you have a
MAUI scheduler you should specify the \char`\"{}MAUI\char`\"{} value
since it modifies the way the queue resources are calculated. By default
the \char`\"{}FIFO\char`\"{} scheduler type is assumed.
\item \texttt{maui\_bin\_path} from the \texttt{{[}queue/queuename]} block
sets the path of the maui commands like \texttt{showbf} when \char`\"{}MAUI\char`\"{}
is specified as \texttt{scheduling\_policy} value. This parameter
can be set in the \texttt{{[}common]} block as well. 
\item \texttt{queue\_node\_string} of the \texttt{{[}queue/queuename]} block
can be used similar to the \texttt{dedicated\_node\_string}. In PBS
you can assign nodes to a queue (or a queue to nodes) by using the
\texttt{node property} PBS node configuration method and assigning
the marked nodes to the queue (setting the \texttt{resources\_default.neednodes}
= \texttt{queue\_node\_string} for that queue). This parameter should
contain the \texttt{node property} string of the queue-assigned nodes.
Setting the \texttt{queue\_node\_string} changes how the queue-totalcpus,
user freecpus are determined for this queue. 
\end{itemize}

\subsubsection{Implementation details}

The job control batch interface makes use of the \texttt{qsub} command
to submit native PBS jobscripts to the batch system. The following
options are used: 

-l nodes, cput, walltime, pvmem, pmem, 

-W stagein, stageout

-e, -j eo

-q

-A 

-N 

For job cancellation the \texttt{qdel} command is used. To find completed
jobs, i.e. to scan for finished jobs the \texttt{qstat} command or
the \texttt{PBS server log file} is used.

The information system interface utilizes the \texttt{qstat -f -Q
queuename} and \texttt{qstat -f queuename} commands to obtain detailed
job and queue information. \texttt{qmgr -c \char`\"{}list server\char`\"{}}
is used to determine PBS flavour and version. The \texttt{pbsnodes}
command is used to calculate total/used/free cpus within the cluster.
In case of a Maui scheduller the \texttt{showbf} command is used to
determine user freecpu values. All these external PBS commands are
interfaced via parsing the commands' output.


\subsubsection{Known limitations}

Some of the limitations are already mentioned under the PBS deployment
requirements. No support for routing queues, difficulty of treating
overlapping queues, the complexity of node string specifications for
parallel jobs are the main shortcomings.


\subsection{Condor}

The Condor \cite{Condor} system, developed at the University of Wisconsin-Madison,
was initially used to harness free cpu cycles of workstations. Over
time it has evolved into a complex system with many grid-oriented
features. Condor is available on a large variety of platforms.


\subsubsection{Recommended batch system configuration}

Install Condor on the Grid Manager (GM) node and configure it as a
submit machine. Next, you must add the following to the node's Condor
configuration (\texttt{CONDOR\_IDS} can also be an environment variable):

\texttt{MAIL = <ARC\_install\_prefix>/libexec/finish-condor-job}

\texttt{CONDOR\_IDS = 0.0}

The \texttt{MAIL} attribute will instruct Condor to run the specified
program on job completion. The default on Condor is to run /bin/mail
to notify the user, but in this case, it is the GM that needs the
notification. Therefore, /bin/mail is replaced with a program especially
written for talking to the GM.

\texttt{CONDOR\_IDS} has to be 0.0, so that the above notification
program can access the Grid job's session directories (needed to extract
the job exit code from the Condor log).

Make sure that no normal users are allowed to submit Condor jobs from
this node. For one thing, it would not work for the user, since Condor
will try to notify the GM instead of the job owner on job completion.
If you don't allow normal user logins on the GM machine, then you
don't have to do anything. If you for some reason want to allow users
to log into the GM machine, simply don't allow them to execute the
condor\_submit program. This can be done by putting all local Unix
users allocated to the Grid in a single group, e.g. 'griduser', and
then setting the file ownership and permissions on condor\_submit
like this:

\texttt{chgrp griduser \$condor\_location/bin/condor\_submit}

\texttt{chmod 750 \$condor\_location/bin/condor\_submit }


\subsubsection{Relevant arc.conf options}

\begin{itemize}
\item The Condor batch system back-end is enabled by setting \texttt{lrms=\char`\"{}condor\char`\"{}}
in the \texttt{{[}common]} configuration block. 
\item \texttt{condor\_location} configuration variable of the \texttt{{[}common]}
block should be set to the Condor install prefix (i.e., the directory
containing Condor's bin, sbin, etc).
\item \texttt{condor\_config} configuration variable of the \texttt{{[}common]}
block should be set to the value the environment variable \texttt{CONDOR\_CONFIG}
should have (but don't try to use the environment variable directly
as \texttt{\$CONDOR\_CONFIG}, since it will probably not be defined
when arc.conf is parsed!)
\item \texttt{condor\_rank} configuration variable of the \texttt{{[}common]}
block, if defined, will cause the \texttt{Rank} attribute to be set
in each job description submitted to Condor. Use this option if you
are not happy with the way Condor picks out nodes when running jobs
and want to define your own ranking algorithm. \texttt{condor\_rank}
should be set to a ClassAd float expression that you could use in
the \texttt{Rank} attribute in a Condor job description. For example:
\end{itemize}
\begin{quote}
\texttt{condor\_rank=\char`\"{}(1-LoadAvg/2){*}(1-LoadAvg/2){*}Memory/1000{*}KFlops/1000000\char`\"{} }
\end{quote}
\begin{itemize}
\item \texttt{condor\_requirements} configuration variable of the \texttt{{[}queue]}
block defined a subpool of condor nodes. See next section for details.
\end{itemize}

\subsubsection{Implementation details}

The job control part of the interface uses the \texttt{condor\_submit}
command to submit jobs. Some of the options used in the job's ClassAd
are:

\texttt{Requirements} -- is used to select the nodes that may run
the job. This is how ARC queues are implemented for Condor.

\texttt{Periodic\_remove} -- is used to enforce cputime and walltime
limits.

\texttt{Log} -- the job's condor log file is parsed by the information
scripts to find out whether the job was suspended.

The information system component uses the following Condor commands:

\texttt{condor\_status -long} -- for collecting information about
nodes

\texttt{condor\_status -format \char`\"{}\%s\textbackslash{}n\char`\"{}
Machine -constraint '...'} -- for listing nodes that make up an ARC
queue.

\texttt{condor\_q -long -global} -- for monitoring running jobs.

\texttt{condor\_history -l jobid} -- for collecting information about
finished jobs. Further cues are taken from the job's condor log file
and the body of the email sent by Condor when a job completes. 


\subsubsection{Configuring Queues}

Condor does not support queues in the classical sense. It is possible,
however, to divide the Condor pool in several sub-pools. An ARC 'queue'
is then nothing more than a subset of nodes from the Condor pool.

Which nodes go into which queue is defined using the \texttt{condor\_requirements}
configuration option in the corresponding \texttt{{[}queue]} section.
It's value must be a well-formed constraint string that is accepted
by a \texttt{condor\_status -constraint '...'} command. Internally,
this constraint string is used to determine the list of nodes belonging
to a queue. This string can get quite long, so, for readability reasons
it is allowed to split it up into pieces by using multiple \texttt{condor\_requirements}
options. The full constrains string will be reconstructed by concatenating
all pieces.

Queues should be defined in such a way that their nodes all match
the information available in ARC about the queue. A good start is
for the \texttt{condor\_requirements} attribute to contain restrictions
on the following: \texttt{Opsys}, \texttt{Arch}, \texttt{Memory} and
\texttt{Disk}. If you wish to configure more than one queue, it's
good to have queues defined in such a way that they do not overlap.
In the following example disjoint memory ranges are used to ensure
this:

\begin{quote}
\texttt{{[}queue/large] condor\_requirements=\char`\"{}(Opsys == \char`\"{}linux\char`\"{}
\&\& (Arch == \char`\"{}intel\char`\"{} || Arch == \char`\"{}x86\_64\char`\"{})\char`\"{}
condor\_requirements=\char`\"{} \&\& (Disk > 30000000 \&\& Memory
> 2000)\char`\"{}}

\texttt{{[}queue/small] condor\_requirements=\char`\"{}(Opsys == \char`\"{}linux\char`\"{}
\&\& (Arch == \char`\"{}intel\char`\"{} || Arch == \char`\"{}x86\_64\char`\"{})\char`\"{}
condor\_requirements=\char`\"{} \&\& (Disk > 30000000 \&\& Memory
<= 2000 \&\& Memory > 1000)\char`\"{}}
\end{quote}
Note that '\texttt{nodememory}' attribute in arc.conf means the maximum
memory available for jobs, while the Memory attribute in Condor is
the physical memory of the machine. To avoid swapping (and these are
probably not dedicated machines!), make sure that '\texttt{nodememory}'
is smaller than the minimum physical memory of the machines in that
queue. If for example the smallest node in a queue has 1Gb memory,
then it would be sensible to use \texttt{nodememory=\char`\"{}850\char`\"{}}
for the maximum job size.

In case you want more precise control over which nodes are available
for grid jobs, using pre-defined ClassAds attributes (like in the
example above) might not be sufficient. Fortunately, it's possible
to mark nodes by using some custom attribute, say \texttt{NORDUGRID\_RESOURCE}.
This is accomplished by adding a parameter to the node's local Condor
configuration file, and then adding that parameter to \texttt{STARTD\_EXPRS}:

\begin{quote}
\texttt{NORDUGRID\_RESOURCE = True }

\texttt{STARTD\_EXPRS = NORDUGRID\_RESOURCE, \$(STARTD\_EXPRS)}
\end{quote}
Now queues can be restricted to contain only 'good' nodes. Just add
to each \texttt{{[}queue]} section in arc.conf:

\begin{quote}
\texttt{condor\_requirements=\char`\"{} \&\& NORDUGRID\_RESOURCE\char`\"{} }
\end{quote}

\subsubsection{Known limitations}

Only Vanilla universe is supported. MPI universe (for multi-CPU jobs)
is not supported. Neither is Java universe (for running Java executables).
ARC can only send jobs to Linux machines in the Condor pool, therefore
excluding other unixes and Windows destinations. The session directory
must be on a network shared directory, visible from all worker nodes. 


\subsection{LoadLeveler}

LoadLeveler(LL), or Tivoli Workload Scheduler LoadLeveler in full,
is a parallel job scheduling system developed by IBM. 


\subsubsection{Recommended batch system configuration}

The back-end should work fine with a standard installation of LoadLeveler.
For the back-end to report the correct memory usage and cputime spent,
while running. LoadLeveler has to be set-up to show this data in the
llq command. Normally this is turned off for performance reasons.
It is up to the cluster administrator to decide whether or not to
publish this information. The back-end will work whether or not this
is turned on.


\subsubsection{Relevant arc.conf options}

Only the two basic LRMS config options are relevant for LoadLeveler:

\begin{itemize}
\item The LoadLeveler batch system back-end is enabled by setting \texttt{lrms=\char`\"{}ll\char`\"{}}
in the \texttt{{[}common]} configuration block. 
\item \texttt{ll\_bin\_path} configuration variable of the \texttt{{[}common]}
block must be set to the path of the LoadLeveler binaries.
\end{itemize}

\subsubsection{Implementation details}

The LoadLeveler back-end uses LoadLeveler's command line interface(CLI)
commands to submit and cancel jobs. All information in the information
system is similarly parsed from the output of CLI commands. It does
not parse any log files, nor does it use the binary APIs. The reason
that the back-end is completely based on the CLI is that the log files
are normally kept on another machine than the front end and that the
binary API for LL changes quite often. Often with each new version
of LL.  


\subsubsection{Known limitations}

There is at the moment no support for parallel jobs on the LoadLeveler
back-end. 


\subsection{Fork}

The Fork back-end is a simple back-end that interfaces to the local
machine i.e. there is no batch system underneath. It simply forks
the job, hence the name. The back-end then uses standard posix commands(e.g.
ps or kill) to manage the job.


\subsubsection{Recommended batch system configuration}

Since fork is a simple back-end and does not use any batch system,
there is no specific configuration needed of the underlying system.


\subsubsection{Relevant arc.conf options}

\begin{itemize}
\item The Fork back-end is enabled by setting \texttt{lrms=\char`\"{}fork\char`\"{}}
in the \texttt{{[}common]} configuration block. 
\item The queue must be named {}``fork'' in the queue section.
\item fork\_job\_limit=\char`\"{}cpunumber\char`\"{}, this option is used
to set the number of running grid jobs on the fork machine, allowing
a multi core machine to use some or all of its cores for Grid jobs.
The default value is 1. 
\end{itemize}

\subsubsection{Implementation details and known limitations}

The Fork backend implements an interface to the {}``fork'' unix
command which is not a batch system. Therefore the backend should
rather be seen as an interface to the operating system itself. Most
of the {}``batch system values'' are determined from the operating
system (e.g. cpu load) or manually set in the configuration file. 

Fork is not a batch system, therefore many of the queue specific attributes
or detailed job information is not available. The support for the
{}``Fork batch system'' was introduced so that quick deployments
and testing of the middleware can be possible without dealing with
deployment of a real batch system since fork is available on every
unix box. The Fork backend is not recommended to be used in production.
The backend by its nature, has lots of limitations, for example does
not support parallel jobs. 


\subsection{LSF}


\subsubsection{Recommended batch system configuration}

Set up one or more LSF queues dedicated for access by grid users.
All nodes in these queues should have a resource type which corresponds
to the one of the the frontend and which is reported to the outside.
The resource type needs to be set properly in the 'lsb.queues' configuration
file. Be aware that LSF distinguishes between 32 and 64 bit for Linux.
For a homogeneous cluster, the 'type==any' option is convenient alternative. 

Example: In lsb.queues set either of the following: 

\begin{itemize}
\item RES\_REQ = type==X86\_64 
\item RES\_REQ = type==any 
\end{itemize}
See the '-R' option of the bsub command man page for more explanation.


\subsubsection{Relevant arc.conf options}

The LSF back-end requires that the following options are specified:

\begin{itemize}
\item \texttt{lrms=\char`\"{}lsf\char`\"{}} in the \texttt{{[}common]} configuration
block. 
\item \texttt{lsf\_bin\_path} configuration variable of the \texttt{{[}common]}
block must be set to the path of the LSF binaries.
\item lsf\_profile\_path must be set to the filename of the LSF profile
that the back-end should use. 
\end{itemize}
Furthermore it is very important to specify the correct architecture
for a given queue in arc.conf. Because the architecture flag is rarely
set in the xRSL file the LSF back-end will automatically set the architecture
to match the chosen queue. LSF's standard behaviour is to assume the
same architecture as the frontend. This will fail for instance if
the frontend is a 32 bit machine and all the cluster resources are
64 bit.If this is not done the result will be jobs eing rejected by
LSF because LSF believes there are no useful resources available.


\subsubsection{Implementation details}

The LSF implementation of the back-end are based solely on parsing
and running LSF's command line interface commands. No log files or
other methods are used. To get the correct output o any output at
all the back-end needs to have an apropriate LSF profile. The path
to this profile must be set in arc.conf. It will then be executed
by the back-end before running any of LSF's CLI commands.


\subsubsection{Known limitations}

Parallel jobs have not been tested on the LSF back-end.

The back-end does not at present support reporting different number
of free CPUs per user.


\subsection{SGE}

Sun Grid Engine, formely known as Codine, is an open source batch
system maintained by Sun. Runs on Linux, Solaris.


\subsubsection{Recommended batch system configuration}

Set up one or more SGE queues for access by grid users. Queues can
be shared by normal and grid users. In case you want to set up nore
than one ARC queue, make sure that the corresponding SGE queues have
no shared nodes among them. Otherwise the counts of free and occupied
CPUs might be wrong. Only SGE versions 6 and above are supported.


\subsubsection{Relevant arc.conf options}

The SGE back-end requires that the following options are specified:

\begin{itemize}
\item The SGE batch system back-end is enabled by setting \texttt{lrms=\char`\"{}sge\char`\"{}}
in the \texttt{{[}common]} configuration block. 
\item \texttt{sge\_root} must be set to SGE's install root.
\item \texttt{sge\_bin\_path} configuration variable of the \texttt{{[}common]}
block must be set to the path of the SGE binaries.
\item \texttt{sge\_cell}, \texttt{sge\_qmaster\_port} and \texttt{sge\_execd\_port}
options might be necessary to set in special cases. See the \texttt{arc.conf(5)}
man page for more details.
\item \texttt{sge\_jobopts} configuration variable of the \texttt{{[}queue]}
block can be used to add custom SGE options to job scripts submitted
to SGE. Consult SGE documentation for possible options.
\end{itemize}
Example:

\texttt{lrms=\char`\"{}sge\char`\"{}}

\texttt{sge\_root=\char`\"{}/opt/n1ge6\char`\"{}}

\texttt{sge\_bin\_path=\char`\"{}/opt/n1ge6/bin/lx24-x86\char`\"{}}

\texttt{...}

\texttt{{[}queue/long]}

\texttt{sge\_jobopts=\char`\"{}-P atlas -r yes\char`\"{}}


\subsubsection{Implementation details}

The SGE backend's commands are similar to the PBS commands. These
commands are used in the code:

Submit job: 

\begin{itemize}
\item qsub -S /bin/sh (specifies the interpreting shell for the job)
\end{itemize}
Get jobs status: 

If the job state is not suspended, running or pending then its state
is failed.

\begin{itemize}
\item qstat -u '{*}' -s rs (show the running and suspended jobs status)
\item qstat -u '{*}' -s p (show the pending jobs status)
\item qstat -j job\_id (long job information)
\item qacct -j job\_id (finished job report)
\end{itemize}
Job terminating:

\begin{itemize}
\item qdel job\_id (delete Sun Grid Engine job from the queue)
\end{itemize}
Queue commands:

\begin{itemize}
\item qconf -spl (show a list of all currently defined parallel environments)
\item qconf -sql (show a list of all queues)
\item qconf -sep (show a list of all licensed processors/slots)
\item qstat -g c (display cluster queue summary)
\item qconf -sconf global (show global configuration)
\item qconf -sq queue\_name (show the given queue cofiguration)
\end{itemize}
Other:

\begin{itemize}
\item qstat -help (show Sun Grid Engine's version and type)
\end{itemize}

\subsubsection{Known limitations}

Multi-CPU support is not well tested. All users are shown with the
same quotas in infosys, even if they are mapped to different local
users. The requirement that one ARC queue maps to one SGE queue is
too restrictive, as the SGE's notion of a queue differs widely from
ARC's definition. The flexibility available in SGE for defining policies
is difficult to accurately translate into nordugrid's information
schema. The closest equivalent of nordugrid-queue-maxqueuable is a
per-cluster limit in SGE, and the value of nordugrid-queue-localqueued
is not well defined if pending jobs can have multiple destination
queues. 

\section{ARC1}
This section contains the current implementation of the ARC1 back-ends.

\subsection{The Information System}
ARC1 provides support for both the classic NorduGrid information schema\cite{INFOSYS} as well as an early minimal GLUE 2 implementation. The functionality is divided between several information collecting scripts and the output is rendered in XML format. Further details about each script are given in the subsections below.
The current GLUE 2 implementation is given in section Section 5.2.

\subsubsection{The information Collector Scripts}
The information collector scripts are divided between several seperate scripts:
\begin{itemize}
\item \texttt{cluster+qju.pl} - driver for information collection. It calls all other infomation collectors and prints results in XML. The information collection is done by one single invocation of this script
\item \texttt{InfoCollector.pm} - base class for all information collectors (i.e.: all files \texttt{*Info.pm})
\item \texttt{InfoChecker.pm} - used by InfoCollector to validate options and results against a simple 'schema' (not XML Schema)
\item \texttt{GMJobsInfo.pm} - collects information about jobs from grid manager status files
\item \texttt{HostInfo.pm} - collects other information that can be collected on the front end (hostname, software version, disk space for users, installed certificates, Runtime environments ...)
\item \texttt{LRMSInfo.pm} - collects information that is LRMS specific (queues, jobs, local user limits ...)
\item \texttt{BATCH\_SYSTEM\_NAME.pm} - plugins for LRMSInfo. Only Fork, SGE and PBS are updated to the new framework
\item \texttt{ARC0ClusterInfo.pm} - combines all information about A-REX and produces information structured according to the classic NG schema
\item \texttt{ARC1ClusterInfo.pm} - combines all information about A-REX and produces information structured according to the GLUE2 schema
\item \texttt{ARC0ClusterSchema.pm} - description of the info produced by ARC0ClusterInfo
\item \texttt{ARC1ClusterSchema.pm} - description of the info produced by ARC1ClusterInfo
\end{itemize}

All information about the hosting environment and queues is collected by one invocation of a perl script called \texttt{cluster+qju.pl}. The XML output is printed to \texttt{STDOUT} and it includes two representations of the output data, namely the classic NorduGrid information schema and an incomplete GLUE2 schema representation.


\subsection{The ARC GLUE 2 implementation}
Currently, the the following GLUE2 classes are included in ARC1:
\begin{itemize}
\item ComputingService
\item ComputingEndpoint
\item ComputingShare
\end{itemize}

While the following classes are still missing (TODO: According to our table in wiki, there should be some other sections as well):
\begin{itemize}
\item ApplicationEnvironment
\item ExecutionEnvironment
\item ComputingActivity
\item Policy including MappingPolicy / AccessPolicy
\end{itemize}

The different classes with their attributes are described in their respective sections below.

\subsubsection{ApplicationEnvironment}

\phantomsection
%\addcontentsline{toc}{subsubsection}{LocalID}
\hspace*{0.5cm}
\begin{shaded}
\textbf{LocalID}
\end{shaded}
\begin{tabular}{lp{10cm}}  
Attribute value:& LocalID\_t\\
Example:&  \verb#TODO#\\
Related xRSL:& \verb#NA#\\
UI role:& TODO \\

\end{tabular}

Description: An opaque identifier local to the Computing Service.

\phantomsection
%\addcontentsline{toc}{subsubsection}{Name}
\hspace*{0.5cm}
\begin{shaded}
\textbf{Name}
\end{shaded}
\begin{tabular}{lp{10cm}}  
Attribute value:& String\\
Example:& \verb#Name: TODO#\\
Related xRSL:& TODO\\
UI role:& ?\\
\end{tabular}

Description: Name of the application environment.

\phantomsection
%\addcontentsline{toc}{subsubsection}{Version}
\hspace*{0.5cm}
\begin{shaded}
\textbf{Version}
\end{shaded}
\begin{tabular}{lp{10cm}}  
Attribute value:& String\\
Example:& \verb#Version: TODO#\\
Related xRSL:& TODO\\
UI role:& TODO\\
\end{tabular}

Description: Version of the application environment.


\begin{thebibliography}{1}
\bibitem{ARC}\char`\"{}Advanced Resource Connector middleware for
lightweight computational Grids\char`\"{}. M.Ellert et al., Future
Generation Computer Systems 23 (2007) 219-240. 

\bibitem{GM}The NorduGrid Grid Manager And GridFTP Server: Description
And Administrator's Manual {[}NORDUGRID-TECH-2], A.Konstantinov

\bibitem{INFOSYS}\char`\"{}The NorduGrid/ARC Information System\char`\"{}
{[}NORDUGRID-TECH-4], B.Kónya

\bibitem{subversion}NorduGrid subversion: http://svn.nordugrid.org/trac/nordugrid/browser

\bibitem{config}ARC configuration document: currently the \texttt{arc.conf.template}
file.

\bibitem{Condor}http://www.cs.wisc.edu/condor/

\bibitem{GLUE2} TODO: ADD REFERENCE
\end{thebibliography}

\end{document}
